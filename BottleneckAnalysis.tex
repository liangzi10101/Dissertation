%% Thesis Template of Chinese Academy of Sciences
%%   for using CASthesis package with LaTeX2e
%%
%% Created by Ling-Yun Wu <aloft@ctex.org>
%%
%% $Id: template.tex,v 1.10 2007/01/09 05:10:46 aloft Exp $


%\documentclass[dvipdfm]{CASthesis}
\documentclass[pdftex]{CASthesis}
% 可选参数：
% notypeinfo 取消扉页的LaTeX版本信息
%
% 下面三个选一个：
% dvipdfm 使用 dvipdfm(x) 生成最终的 PDF 文档 (缺省设置）
% dvips 使用 dvips 生成最终的 PS 文档
% pdftex 使用 pdfLaTeX 生成最终的 PDF 文档


% 设置图形文件的搜索路径
\graphicspath{{chapter/}{figures/}}

% 取消链接的颜色（黑白打印时）
%\hypersetup{colorlinks=false}

% 小节标题靠左对齐
%\CTEXsetup[format+={\flushleft}]{section}

\usepackage[english]{babel}

\usepackage{ReviewCommand}

\usepackage{subfigure}
\usepackage{multirow}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 封面部分
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

  % 中文封面内容

  \serialnumber{001}
  \title{基于特征空间划分的算法级绘制性能瓶颈识别的研究与实现}
  \author{梁子}
  \institute{四川大学计算机(软件)学院}


  % 封面
  \maketitle



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 前言部分
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frontmatter

  % 摘要
 % \include{chapter/Abstract}

  % 目录
  \tableofcontents
  % 表格目录
 % \listoftables
  % 插图目录
  %\listoffigures


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 正文部分
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mainmatter

\section{摘要}

性能瓶颈识别技术对于优化多算法复杂绘制系统的性能至关重要。随着游戏等实时渲染应用的不断发展，用户对高质量渲染画面的需求日益增强，数字游戏以及虚拟现实等应用程序的绘制系统往往需要加入更多的绘制算法以满足用户需求，但更多绘制算法意味着更大计算资源的消耗，这将直接影响实时渲染的性能。一方面，算法实现过程自身的优化成为关注点，另一方面，即使算法本身的实现过程达到最优化，在特定的绘制场景下仍有可能成为影响实时绘制性能的因素，造成绘制的卡顿。因此，性能瓶颈识别技术成为帮助开发人员进一步优化渲染方案的重要手段。

本文以载有若干复杂绘制算法、任意指定动态场景的复杂绘制系统作为研究基础  ，将具有特征空间划分的性能瓶颈识别技术作为研究重点，设计并实现了一种基于特征空间划分的识别性能瓶颈解决方案，旨在绘制系统无法确定全局性能瓶颈时，通过空间划分完成局部性能瓶颈的识别工作，从而在保证渲染效果的基础上，帮助开发人员锁定影响实时绘制性能的算法级瓶颈，减少图像绘制时的卡顿现象。本文在前人利用机器学习构建瓶颈分析模型的工作基础上，提出基于特征空间划分的算法级性能瓶颈识别方案，改进了性能识别不稳定以及非全局最优解问题。本文工作主要内容如下：

\begin{itemize}
	\item 通过预采集性能数据集，细化构建基于回归森林算法的绘制性能评估模型，进一步改进以变量重要性为算法瓶颈度量标准的实现过程；
	\item 针对无法在绘制性能数据集中找到全局性能瓶颈的复杂情况，提出基于特征空间划分数据集的性能瓶颈分析树方案，并设计针对瓶颈分析树的量化评估标准；
	\item 设计实现了不同的性能瓶颈分析树生成策略，包括贪心算法策略和类遗传算法策略。针对类遗传算法策略，以瓶颈分析树的量化评估标准为基础，提出以伪满二叉树的编码方式进行对瓶颈分析树的编、解码任务，进一步完成基于遗传算法、寻找更优瓶颈分析树的工作，改进了前研究方案中瓶颈分析树形态不稳定以及评估得分低的问题；
    \item 另外，本文方法针对变量重要性计算过程中对预采集数据量敏感的现象，进行了进一步验证性工作，以指导瓶颈分析树构建过程的改进；
\end{itemize}

实验结果表明，本文方法能够找到将原始性能数据集进行合理划分的更优解决方案，并且在每个子性能数据集中可以确定出局部性能瓶颈。从而在动态场景中，分别确定出不同的性能瓶颈，进一步帮助开发人员有效地优化渲染的性能。

\textbf{关键词：性能瓶颈分析；瓶颈分析树；贪心算法；遗传算法}

\section{绪论}

\subsection{课题研究背景及意义}

绘制系统的性能优化在实时渲染技术中有极其重要的研究意义和价值。在电子游戏、动画及虚拟现实等领域中，为了不断满足用户追求的画面真实感、沉浸感等，其绘制系统往往需要加入更多的计算机图形学算法，例如全局光照、物理仿真等绘制算法。而更多绘制算法的引入必然会造绘制系统性能的改变，这种改变一般情况下呈负面影响，也就是说会造成系统渲染性能的下降，因此，系统的性能优化也逐渐成为了该领域的研究热点。

绘制系统的性能优化往往可以从不同角度展开。目前为止，图形学领域对于绘制系统性能优化的研究大致可分为以下几个方面。

计算机图形学很重要的一个研究领域就是进行特定绘制算法自身优化的研究，通过完成对特定算法的优化，在保持甚至提高原有渲染效果的基础上，提高绘制效率。例如：基于级联纹理的圆锥追踪动态全局光照算法\cite{Crassin2011Interactive}，该算法进一步优化了全局光照算法，通过基于级联纹理的圆锥追踪近似模拟物体表面的BRDF光照计算模型，极大减简化了该公式的计算复杂度，从而加速全局光照算法的绘制效率。从算法本身进行优化最大的问题在于：该优化往往仅关注自身算法的优化过程，并不会进一步考虑结合多种算法的复杂绘制系统中，各个绘制算法之间是否存在相互影响或者相互重叠的部分，也就是说，该角度入手的优化方式对任意特定算法具有普适性，对绘制系统本身不具有普适性。

基于应用程序接口的优化可以解决上述问题，该角度不再将关注点放到某个特定的算法上，而是从更底层的算法调用的绘制指令等入手，完成对绘制性能的进一步优化。以OpenGL为例，OpenGL 是用于渲染2D、3D 矢量图形的跨语言、跨平台图形库，它为图形的渲染工作管理着一套完整的绘制指令集合以及绘制状态，在不同的绘制状态下，各个绘制算法实际上是通过调用一系列绘制指令来真正执行完成绘制算法的，而实际情况是：不同的绘制算法之间很可能存在重叠的指令执行部分、冗余的绘制状态改变等，因此基于绘制指令集的优化通过进一步精简这些部分可以进一步解决这样的优化问题。然而，即使解决了上述问题仍然无法保证绘制系统已经不存在进一步优化的空间。其原因在于：该角度的优化默认各个绘制算法在逻辑上已经处于最优状态，但这几乎是不可能的。

举个简单的例子：假设一个渲染场景中需要完成某个位置的爆炸效果渲染，爆炸场景最终渲染的视觉效果假设由爆炸粒子的个数和爆炸粒子本身的半径正向决定，即：爆炸粒子个数越多、半径越大，爆炸效果越细腻。而事实上，当粒子个数达到一定数量时，爆炸效果在人眼的角度观察差别几乎不大，但此时粒子个数很可能已经严重影响到这个绘制算法的效率。而对于这种情况，通常是具有经验的图形开发者凭借经验进行调试优化。当系统仅包含单个算法或算法之间不存在相互影响时，这样的优化是简单有效的，但绘制系统逐渐复杂时，直观的经验可能无法给出进一步的优化指导。例如：如果在上述爆破场景中进一步引入半透明物体的渲染算法\cite{Maule2012Memory}，当场景中可见透明物体很少时，粒子个数或粒子半径仍然是影响绘制效率的瓶颈因素，但当场景中可见透明物体逐渐增加并达到一定阈值时，关于该透明算法的一些参数很可能已经超过爆破粒子个数和半径，成为了当前情况下的瓶颈因素。而随着系统引入算法的数量逐渐增加时，凭借经验给出指导优化变得尤其困难。类似像爆炸粒子个数、粒子半径和可见透明物体面积等这样在算法参数级别上影响系统绘制效率的因素我们称之为：算法级绘制参数。

算法级绘制参数的性能瓶颈识别技术能够很好的解决上述问题。该技术从算法逻辑参数的角度出发，旨在从算法层面寻找一种更通用的瓶颈识别方案：在给定的、载有多算法的绘制系统中，找到影响系统效率的算法级别的因素，从而帮助开发者进一步优化系统的绘制效率。

本课题基于算法级绘制参数的性能瓶颈识别技术，并以此作为研究切入点，在绘制系统满足指定渲染效果的前提下，针对该系统的实时性能，提出基于大数据分析的绘制系统性能瓶颈的自动识别方法，旨在利用数据挖掘的方法，基于绘制系统中绘制算法参数与绘制时间的关系模型，识别绘制系统中成为性能瓶颈的绘制算法参数，重点研究在无法识别到全局绘制性能瓶颈的情况下，通过特征空间划分实现各个子空间局部性能瓶颈的确定工作，进一步指导实时绘制系统的开发者：在满足绘制效果的前提下，如何调整绘制算法的参数，以获得高效的绘制效率。

除此之外，基于硬件的优化也是提高系统绘制性能的优化方案，但并不在本文讨论研究的范围之内。

\subsection{国内外研究现状}

对绘制系统的性能优化可以从上述多个角度进行展开，图形学研究者与图形软硬件开发商以不同的方式完成各自的研究，因此本节将从多个角度出发，介绍国内外绘制性能瓶颈识别技术的研究发展现状。由于图形学领域基于图形算法优化的内容因渲染目的各异且算法针对性强的特点，并不具有普适的讨论意义，因此本节并不会将其纳入到讨论范围内。本节更多的将着眼点放在基于应用程序接口级别的性能瓶颈识别与基于算法级别的性能瓶颈识别两大方面。

\subsubsection{基于应用程序接口级别的性能瓶颈识别}

图形硬件开发商特别是显卡制造厂商在提供高性能显卡硬件的同时，为了、最大限度提供图形硬件的底层支持、帮助开发人员进一步挖掘硬件提供的渲染性能，往往会配套开发出不同的性能分析工具，这些工具提供应用程序接口级别的调试、性能分析信息。

\textbf{Inter Graphics Performance Analysis 工具}

Inter Graphics Performance Analysis 工具\cite{InterGPA} 是基于图形绘制的性能分析软件，它提供基于Inter HD Graphics （IHD）硬件平台下图形渲染的性能分析指导方案，通过其提供的一套应用程序接口，可视化、语言无关地给出开发人员在渲染过程中存在的性能问题\cite{OptimizeYourUnityGames}\cite{ApplicationsUsingIntel}，这里的语言无关是指：图形开发人员可以使用Microsoft 系统提供的Direct-X 语言、或者其他跨平台的图形开发库例如OpenGL 等，其给出的性能分析信息更多从底层的绘制指令接口角度出发，与载入的图形算法无关。

Inter Graphics Performance Analysis 工具大致包含如下功能组件：

\begin{itemize}
	\item Monitor：将Inter Graphics Performance Analysis 工具连接至用户的应用，为HUD （Head Up Display）模式以及键盘快捷键等完成配置工作；
	\item System Analyzer；实时查看CPU、GPU、 图形API 以及能源消耗指标，同时为绘制性能改进从指令集的角度给出简单的指导性建议；
	\item Platform Analyzer；将CPU 以及GPU 上承载的应用程序和其线程间的交互进行可视化管理；
    \item Graphics Frame Analyzer；完成单帧绘制结果的快照捕捉，并进行该帧内容的分析与指标显示，大致包含着色器、绘制状态、像素历史记录、纹理数据等信息的详细报告；
    \item Graphics Trace Analyzer；评估当前应用程序运行时，CPU 以及GPU 的工作负载性能，从而进一步保证在图形渲染过程中能够最大限度地发挥Inter HD Graphics 架构的处理能力；
\end{itemize}

近些年，越来越多的成熟商业应用构建在Inter HD Graphics（IHD）硬件平台架构上，并以Inter Graphics Performance Analysis 分析工具帮助完成了从研究到工业化的转型。在 Intel? GPA 的支持下，在配置 Intel? 4 系列高速芯片组显卡的机器上运行网络游戏《JX Online World 3》 时，西山居研发团队进一步将该款游戏的整体可播放帧率提高了 2.1 倍\cite{JX3Game}。巨人网络研发团队通过 Intel? GPA 发现了游戏《King of Soldier》 在绘制阴影，射击武器，施法念咒及角色的效果上的优化空间。在配置了第三代英特尔酷睿处理器的电脑上，《King of Soldier》 的运行性能从图像密集型场景中的每秒 12 帧提高到了每秒 21 帧\cite{OptimizingKingofSoldier}。《Xuanyuan Legend》是腾讯北极光工作室在2012 年11 月发布的首款3D浅规则战斗网游，采用新一代国际顶级引擎Gamebryo Element 2.3\cite{GamebryoInfo}，辅以丰富的动态效果和光影效果，带来出色画面层次感。腾讯开发团队通过使用 Intel? GPA 来分析代表性场景并找出瓶颈，该团队对阴影贴图生成，天空盒剔除，地形渲染， UI 图像缓存以及缩小纹理进行了改进，通过这一系列渲染技术上的改进，完成了游戏绘制帧率从每秒 53 帧提高到71 帧的提升\cite{OptimizingXuanYuan}，为用户提供出色的游戏体验。 针对 Ubisoft 团队开发的动作冒险游戏《Splinter Cell: Blacklist》，开发人员使用 Intel? GPA 分析发现游戏中光照及阴影的绘制极大地影响了整体性能。经过优化改进后，这款游戏的帧率大约提高了 3 倍
\cite{OptimizingSplinterCellBlacklist}。 配置第四代英特尔酷睿 i7 处理器的台式机，该款游戏的帧率分别达到了低配版的每秒 43 帧及中配版的每秒 35 帧。

\textbf{NVIDIA Nsight}

NVIDIA Nsight\cite{NVIDIANsight}\cite{GPUProgrammingGuideGeForce}\cite{NVIDIAParallelNsight}\cite{Nvidiaparallelnsighttm} 是一个功能强大的调试及性能分析工具，它的强大主要表现在两大方面：帮助图形开发人员调试渲染应用程序，使其更好地理解代码、可视化观察系统行为活动；同时通过可视化的应用程序接口辅助开发人员了解程序使用CPU、GPU 的情况，便于开发人员分析和识别指令集性能瓶颈，为进一步的优化工作提供基础。

NVIDIA Nsight 是全球首个集成在 Microsoft Visual Studio 中的图形开发平台。NVIDIA Nsight Visual Studio Edition\cite{NVIDIANsightVisualStudioEdition}\cite{NVIDIANsightUserGuide}\cite{NVIDIANsightCUDA} 是适用于在英伟达的GPU
上运行的CUDA(Compute Unified Device Architecture) 及图形应用程序的开发环境。借助 NVIDIA Nsight，开发人员可以在 Microsoft Visual Studio 中使用CUDA 调试器，图形调试器以及分析和配置工具，其具体功能如下：

\begin{itemize}
	\item CUDA Debugger: 帮助开发者调试 CUDA 应用程序，例如在 CUDA 源代码中设置断点，检查内存，查看本地变量的值以及执行其他常见的调试任务；
    \item Graphics Debugger: 允许开发人员通过指令操作捕捉帧并调试当前帧，例如调试顶点着色器，像素着色器以及查看管道情况；
    \item Analysis and Profiling Tools: 辅助开发人员了解工作负载在应用程序和整个系统中的分布，例如查看CUDA/OpenGL/DirectX 调用、内存拷贝、内核执行以及 CPU/GPU 活动事件。
\end{itemize}

NVIDIA Nsight 应用于包括游戏开发，高性能计算\cite{DebuggingMassivelyParallelApplications} 及超级计算等多个不同的领域。 BioWare 艾德蒙顿工作室利用 NVIDIA Nsight 加速了游戏《Dragon Age 2》 在 GPU 上的运行性能\cite{DragonAge}。 对于安卓游戏《Space Ark》\cite{AndroidGameswithNVIDIA}，Strawdog Studios 通过使用 NVIDIA Nsight Tegra 专为 NVIDIA Tegra 3 以上的处理器进行了特别优化，其中，NVIDIA Nsight Tegra\cite{NVIDIANsightTegra} 专用于开发、构建、调试和部署安卓系统原生应用程序。

\subsubsection{基于算法参数级别的性能瓶颈识别}

绘制算法一般包括多个特定的参数来控制算法中不同实现细节的绘制质量，例如在屏幕空间环境光遮蔽（Screen Space Ambient Occlusion，SSAO）\cite{Bavoil2009Multi}算法中，为计算遮挡率而采集每个像素周围深度样本的个数决定了环境光照的绘制质量，另外，用于模糊处理每个像素的滤波半径决定了去噪的质量。所有这些特定于算法的参数都可能与绘制系统的性能相关。因此，针对算法级别的性能瓶颈分析主要考虑各个绘制算法本身的内在因素对绘制性能的影响。

基于算法参数级别的性能瓶颈识别已经不再关注与底层对接的绘制接口调用部分，其将关注点更多的放在算法级别的参数对绘制效率的影响，该角度强调参数对结果的影响，而对算法普适，无论载入绘制系统的算法具体是什么，只要算法可以提供影响最终绘制效率的算法级参数，该思想就是有效的。

目前基于算法参数级别的性能瓶颈识别仍处在理论研究阶段，该领域需要更多的理论创新推动其不断发展。利用机器学习的思想解决该问题是一个非常重要的技术创新。其中有许多可以与本研究问题结合的部分。简言之，算法级参数可以抽象成机器学习思想中“特征”这一概念、绘制效率相应抽象成“学习结果”这一概念，通过衡量“特征”对“结果”的影响程度，从而确定出重要的“特征”，即：找到参数瓶颈。

\textbf{特征排序算法}

特征排序（Feature Ranking）是机器学习领域重要的应用分支，如何在多个特定于算法的参数中确定性能瓶颈这一问题可以转换为参数的特征排序。在机器学习和模式识别[31]
中，特征是指独立的可衡量的属性或者是观察到的某一现象的特性，针对本研究问题，可以将某个算法参数抽象为一个“特征”，特征影响问题域的能力具体映射为算法参数影响绘制系统的能力，通过对该能力的排序最终识别出哪些算法参数会最终成为性能瓶颈。

特征排序是高层的抽象概念，可以通过不同的具体算法和排序准则完成，例如可以基于统计学、信息论或其他分类器的某些功能选择合理的排序准则来对特征进行评分。

在统计学上，皮尔森相关系数（Pearson Correlation Coefficient，PCC）\cite{10.2307/115794}\cite{article}是一种用来反映因变量与自变量之间线性相关程度的统计量。皮尔森系数的有效取值为[-1, 1]。 若皮尔森相关系数等于 0，表明因变量与自变量间非线性相关。若皮尔森相关系数大于 0，表明因变量与自变量是正相关；反之，则表明因变量与自变量是负相关。皮尔森相关系数的绝对值越大表明因变量与自变量间的相关性越强。

在概率论和信息论中，互信息（Mutual Information，MI）\cite{Chen1996Elements}\cite{Battiti1994Using}使用两个变量之间的依赖性度量作为排序准则。从概念上理解，互信息是一个变量包含另一个变量的信息量，换言之，已知一个变量，另外一个变量减少的信息量则为互信息。互信息是对偶且非负的，当其等于 0 时表示两个变量互不相关。不同于相关系数，互信息不仅能衡量两个变量线性相关的程度，还能衡量变量之间的非线性关系。

Jong 等人\cite{Scheffer2006Proceedings} 受集成学习（Ensemble Learning）\cite{Breiman1998Arcing}的启发提出了集成特征排序（Ensemble Feature Ranking， EFR）。该算法使用了基于遗传算法的学习方法及进化学习算法 ROGER （ROC-based Genetic Learner）\cite{Sebag2003Impact}\cite{Sebag2003ROC}，在处理非线性问题时表现出了良好的性能。

Maldonado 等人\cite{Maldonado2014Feature} 提出了基于线性支持向量机（Support Vector Machine， SVM）的高维特征排序方法。该方法通过线性 SVM 模型计算每个特征的权重，并根据特征权重对特征进行排序。基于线性 SVM 的特征排序方法在 Causality Challenge\cite{DBLP:journals/jmlr/GuyonACEPSS08} 的数据集上已被证明有效。

Zien 等人\cite{Zien2009The}提出了特征重要性排序度量（Feature Importance Ranking Measure，FIRM）方法。该算法实现了一种通用的重要性度量，与基于权重的度量方法相比，该重要性度量方法不容易受特征缩放的影响，具有一定的客观性。

\textbf{变量重要性度量}

变量重要性度量从另外一个角度衡量特征排序。针对不同的数据集或问题类型，存在多种度量方法用于评估变量的重要性。

Shnaider 等人\cite{Shnaider2018Relative} 提出基于传统方法与软回归的评估解释变量的相对重要性在逻辑回归（Logistic Regression）\cite{Thomas1998On}中。Pratt\cite{Mittlb2015Explained} 提出的针对简单线性回归问题测量变量重要性的方法，在基础上\cite{Thomas1998On} 进行了修改。

对于具有高维且未标记的特征的非线性问题，随机森林\cite{Breiman2001Random}\cite{Guyon2006An} 可以用于进行特征排序。随机森林可以通过内部 out-of-bag 估计值提供两种变量重要性度量方法，即 Mean Decrease Accuracy （MDA）重要性评分方法及 Mean Decrease Gini （MDG）重要性评分方法，后者也被称为 Mean Decrease Impurity （MDI）方法。
Louppe 等人\cite{NIPS2013_4928}针对随机森林的 MDI 重要性评分方法进行了理论分析，并总结得到当且仅当变量不相关时，变量的 MDI 重要性等于零，并且相关变量的 MDI 重要性在去除或添加不相关变量的情况下均保持不变的结论。为了更好地反映变量的重要性，Strobl\cite{Strobl2008Conditional} 等人提出了基于随机森林的条件变量重要性。该方法受到 Nason 等人\cite{Nason2004CARTscans} 的启发，区分了变量的条件影响和边际影响。考虑到现实中数据包含缺失值的情况， Hapfelmeier 等人\cite{Hapfelmeier2014A} 通过引入适用于任何类型数据的变量重要性度量方法，提出了克服数据缺失问题的解决方案。 Janitza 等人\cite{Janitza2013An} 检验了在数据分布不平衡的情况下置换变量重要性的性能，并且使用基于AUC （AreaUnder Curve）的重要性度量方法来替换置换变量重要性度量，以达到更加稳健的重要性度量结果。

\subsection{本文主要工作}

本文将研究重点放在利用随机森林算法构建绘制系统模型后，针对全局性能瓶颈无法识别的情况，尝试采用不同的策略对特征空间进行合理的划分以识别出局部性能瓶颈。

\begin{itemize}
    \item 提出“特征空间划分方法”确定局部性能瓶颈

    针对无法在完整绘制性能数据集中找到全局性能瓶颈的复杂情况，提出特征空间超平面划分方法，完成对原绘制性能数据集的划分，旨在确定各子数据空间中的绘制性能瓶颈。各个子空间的性能瓶颈称为局部性能瓶颈。

    \item 完成对“瓶颈分析树”的设计以及量化评估

    不同策略的特征空间划分方法将导致不同的子数据空间划分结果，本文提出“瓶颈分析树”的概念描述数据空间的划分过程以及划分结果，并设计出相应的瓶颈分析树量化评标准，为进一步确定局部性能瓶颈提供基础。换言之：本文提出基于瓶颈分析树的特征空间划分方法。

	\item 两种策略构建瓶颈分析树

    设计实现了不同的性能瓶颈分析树生成策略，包括贪心算法策略和类遗传算法策略。重点研究类遗传算法策略，提出伪满二叉树的编码方式对瓶颈分析树进行编、解码任务，进一步完成基于遗传算法寻找更优瓶颈分析树的工作，改进了贪心算法策略中瓶颈分析树形态不稳定以及瓶颈分析树形态差的问题；

	\item 构建并行化学习模型

    通过预采集性能数据集，实现基于回归森林算法的绘制性能评估模型并行构建过程，进一步完成以变量重要性为算法瓶颈度量标准的并行化实现过程；

    \item 验证变量重要性计算对输入数据量的要求

    本文方法针对变量重要性计算过程中对预采集数据量敏感的现象，进行了进一步验证性工作。具体来说，当学习模型构建完成之后，利用该模型进行变量重要性计算时，用于计算的数据量小于一定阈值之后，所计算得到的变量重要性将不再具有指导意义，本文针对该特性进行具体阈值的验证性工作，以指导瓶颈分析树构建过程的改进。
\end{itemize}

\subsection{本文组织结构}

本文共分为五个章节，各章节的组织结构与核心内容如下：

第一章为绪论部分，主要介绍了本文研究课题的相关背景、现状以及研究意义，并针对识别复杂绘制系统算法级性能瓶颈中遇到的问题进行了阐述，最后对本文的研究内容以及解决的关键性问题进行说明。

第二章为相关算法部分，主要介绍了与本文算法相关的基础算法以及理论基础部分。主要介绍遗传算法、贪心算法的基本原理，以及基于随机森林变量重要性与瓶颈分析树的性能瓶颈识别技术其理论基础与大致实现流程。

第三章为核心算法部分，主要描述了本文基于特征空间划分思想构建瓶颈分析树以识别复杂绘制系统算法级性能瓶颈的实现，以及相关的算法推导，并详细阐述了实现中的难点以及具体细节。

第四章为实验部分，通过实验验证了本文算法的正确性、对比了本文算法中基于贪心策略的瓶颈分析树生成和基于类遗传策略的瓶颈分析树生成之间的具体改进点，从而验证后者的优势。

第五章为总结与展望，对本文基于特征空间划分的复杂绘制系统的优点和缺陷进行了分析，并针对存在的问题以及在此基础上的未来发展方向进行了展望。

\section{相关技术概述}

本章主要介绍课题实现过程中涉及到的相关技术及算法概念，包括：1）遗传算法的基本思想以及核心关注点；2）回归森林技术的基本原理以及测量特征属性重要程度的变量重要性方法；3）OpenMP并行加速技术。

\subsection{遗传算法概述}

遗传算法\cite{Banzhaf1998Genetic}（Genetic Algorithm, GA）是模拟达尔文生物进化论中自然选择和遗传学机理进化过程的计算模型，是一种通过模拟自然进化过程、解决搜索问题全局最优解的通用算法模型。

搜索算法通常情况下是指：利用计算机的高性能来有目的的穷举问题域解空间中非完全或完全解情况并根据给定条件求出问题域的解的算法。常见的搜索算法包括：枚举算法、深度优先搜索、广度优先搜索、A* 算法、回溯算法、蒙特卡洛树搜索以及散列函数等算法。搜索算法实际上是根据初始条件和扩展规则寻找符合目标状态的解的过程，其共同特征为：

\begin{itemize}
    \item 根据初始条件生成一组候选解；
    \item 依据给定的评估条件计算候选解的优秀程度；
    \item 根据优秀程度保留部分候选解，放弃另一部分候选解；
    \item 对保留的候选解进行进一步操作，拓展出新的候选解；
\end{itemize}

不同于其他搜索算法，遗传算法具有以下几方面的特征适用于本研究课题：

\begin{itemize}
    \item 遗传算法关注问题域的若干解集合而不是某个初始解。该特点是遗传算法与传统优化算法最本质的区别。针对传统优化算法，其求解的过程通常是从某个初始解开始，根据确定的拓展规则不断迭代求得最优解。其缺点在于求解的过程容易得到局部最优解，这很大程度上取决于问题域本身的结构特性。例如在贪心算法中，若被研究的问题域满足最优子结构特性，则算法求得的最优解为全局最优解，否则很容易得到局部最优解。而遗传算法从若干解集合开始搜索，覆盖面更大，利于全局择优。
    \item 遗传算法模拟“自然进化，适者生存”的原理具有高度可扩展性。遗传算法从更通用的角度解决搜索问题，这意味着遗传算法不再以“过程”为指导，而是以“结果”为指导，具备“黑盒”特性，即它不关注搜索空间问题域本身的结构以及其它辅助信息（过程），而是通过适应度函数\cite{Banzhaf1998Genetic} 来对某个解个体（结果）进行评估，并在此基础上进行遗传操作\cite{Banzhaf1998Genetic}。此外，适应度函数不仅不受连续可微的约束，同时函数的定义域可以根据实际问题任意指定，这将进一步提高该算法的可扩展性。
    \item 遗传算法易于实现并行化过程。遗传算法关注问题域中解的集合，而集合中所有解本身并不存在相互的关联性，因此，算法对问题空间中的若干解进行构建和生成的过程容易实现并行化技术，这为提高遗传算法实际运算时的效率提供保障。
    \item 遗传算法采用不确定性规则指导其进化搜索的方向，该特点使得进化过程以概率方式进行，使得其优化结果具有统计学意义。同时从另一角度避免算法过早进入局部最优解。不确定性规则表现在多个方面：1）以概率的方式进行淘汰选择以把控进化的方向；2）在进行交叉、变异算子时以恒定或自适应的概率方式进行具体的算子操作。
\end{itemize}

\subsubsection{Markovian遗传模型}

Markovian遗传模型\cite{Vose1999The}是最常见的遗传算法模型，该模型是指种群迭代生成过程仅与当前种群个体有关、在时间序列中“无记忆”进行进化的过程。具体来说，观察某次的进化迭代过程，假设当前种群$P_{n}$处于状态空间$S_n$，前一代种群$P_{n-1}$和下一代种群$P_{n+1}$的状态空间分别为$S_{n-1}$和$S_{n+1}$，则$S_{n+1}$的概率分布只能由$S_n$ 决定，而与时间序列中位于$S_n$之前、包括$s_{n-1}$在内的所有状态均无关联，转换过程如图\ref{Fig.markov}所示，其中函数$\mathbf{p(\ )}$为转换概率。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/markov.png}}
	\caption{Markovian遗传模型的状态转换.}
	\label{Fig.markov}
\end{figure}

\subsubsection{编码}

全局优化\cite{Thomas2009GeneticAlgorithms}中指出遗传算法实际上是进化算法\cite{Thomas2009EvolutionaryAlgorithms}的一个子类，遗传算法不直接对问题域中的各个参数进行处理，即：不对种群个体进行处理，而是将个体进行编码，遗传算法直接作用于该编码结果。

Thomas Weise指出编码策略需要满足三个规范：

\begin{itemize}
    \item 完备性：问题域中的任意解方案总能找到对应的编码表示；
    \item 健全性：编码结果能够完整表示问题域空间中的所有解；
    \item 非冗余性：编码结果与候选解一一对应；
\end{itemize}

遗传算法常见的编码方式包括二进制编码、浮点数编码以及符号编码等，同时根据具体需要解决的问题特点可以设计更为复杂的编码方式。

\textbf{二进制编码}

二进制编码方法类似人类基因组的4种碱基序列\cite{chenshuang2008GeneBasSsequence}，人类基因的每个基因点可以有4种不同的碱基，而二进制编码方式将其简化为2种，分别用0和1表示，这样一个编码位能够表示出2种不同的状态信息，若干0和1的有序序列构成一条编码结果，假设二进制编码序列足够长，则在问题域空间下可以完整且唯一表示所有的解。图\ref{Fig.binaryCoding}是二进制编码的一个例子：

\begin{figure}[!h]
	\centering{
	\includegraphics[width=0.6\linewidth]{figures/binaryCoding.png}}
	\caption{二进制编码，$a_i$表示某个编码位.}
	\label{Fig.binaryCoding}
\end{figure}

二进制编码在遗传算法中得到最广泛的应用，其优点主要包括：1）编码、解码过程简单，易于实现且计算速度快；2）交叉、变异等遗传算子的设计方案简单，计算资源消耗小；3）满足最小字符集编码原则；4）便于利用模式定理\cite{zhouxiyi2006moshidingli}对算法进行理论分析。其缺点在于：针对连续问题的优化表现较差。例如对一个高阶连续函数进行最大值求解，当候选解逐渐逼近于最优解时，离散的二进制编码进行遗传操作后的结果很容易出现变化大、不连续的情况，甚至会出现远离最优解的情况，反复迭代有可能出现震荡现象而得不到最终的全局最优解。而如果为达到精度要求而一味地增加编码长度，虽然能从一定程度上解决该问题，但这将极大地影响算法的效率。一方面增加解码难度，另一方面随着编码维度的增加也使得遗传算法的搜索空间成指数级增长。

\textbf{浮点数编码}

浮点数编码是指个体的每个编码位用某一范围内的浮点数表示，该浮点数成为基因值。在浮点数编码中，任意编码点的基因值有其严格的区间限制，这要求遗传算法中的所有遗传算子（包括交叉算子、变异算子）在进行操作后，新的编码序列对应基因值仍保持在相应的区间范围内。图\ref{Fig.floatCoding}是浮点数编码的一个例子：

\begin{figure}[!h]
	\centering{
	\includegraphics[width=0.6\linewidth]{figures/floatCoding.png}}
	\caption{浮点数编码，$a_i$表示某个编码位，假设$a_i$的取值范围为：[0.0, 10.0).}
	\label{Fig.floatCoding}
\end{figure}

浮点数编码在解决连续函数求最优解的问题上的优点主要包括：1）适用于高精度问题求解；2）善于表示范围较大的数，并利于在较大空间进行搜索；3）在一定程度上降低计算复杂性，提高算法整体运行效率；4）便于处理复杂的决策变量约束条件；

\textbf{排列编码}

排列编码又被称为“符号编码”，排列编码可以针对大部分NP问题，该编码方式将有限集合内的元素进行排列组合，假设符号集合$S=\{a_1, a_2, ..., a_m\}$有\\ $m$个元素，元素$a_i(i \in [1, m])$表示一个无数值含义、有逻辑含义的符号，则理论上问题域的解应该有$m!$种组合情况。

该方法为一些NP问题提供了另一种求解的思路，当$m$较大时，穷举法由于效率问题导致失效，此时利用排列编码的方式、适当设计遗传算法模型可以提高运行效率。例如作业调度问题、旅行商问题以及资源调度问题等。

\subsubsection{适应度函数}

适应度函数的合理设计在指导遗传算法朝着正确方向进化的过程中起到决定性作用。\cite{Thomas2009EvolutionaryAlgorithms}中指出，遗传算法实际通过染色体模拟研究自然界中生物的遗传和进化现象。在生物领域，科学家使用\textbf{适应度}来量化物种中的某一个体对其生存环境的适应程度。在同一物种内。对生存环境适应程度高的个体更容易生存，同时其参与繁殖的几率也会增加，反之，随着时间的推移，个体会逐渐消失。而在生物学领域中，生物个体的基因特性将直接决定该生物在环境中的表现型，个体的表现型与其个体在特定生存环境下的个体适应度是一一对应的，反向推导，选择适应度更高的个体存活并繁衍的过程将间接保留生物个体中优秀的基因特性。遗传算法中的适应度函数借鉴该原理完成对研究问题域解的质量的量化评估，但在自然界中，这种评估模型天然存在，而遗传算法中的适应度评估会根据具体问题域的特性而被设计出不同的适应度函数。适应度函数的值域通常为$[0,+\infty )$的实数。

适应度函数的设计主要满足以下条件：

\begin{itemize}
    \item 单值、连续、非负、最大化；
    \item 合理、一致性；
    \item 计算量小；
\end{itemize}

\subsection{随机森林算法概述}

\subsubsection{回归分析}

回归分析是\cite{1988PracticleRegressionAnalysis}一种统计学分析方法，通过统计分析给定的数据$D$，确定自变量$X$与响应变量$Y$之间的定量关系模型$\mathbf{F}$，参见公式\ref{eq:RegressionAnalysis}。通常情况下，自变量$X$是一个维度为$n(n \geq 1)$的向量，$n$个分量可以被称为特征属性，响应变量$Y$是一个连续变化的量（$Y={y_1, ..., y_m}, m \geq 1$）。回归分析本质上属于监督性学习，并通常将学习结果用于预测分析。

\begin{equation}
\label{eq:RegressionAnalysis}
Y=\mathbf{F}(X)
\end{equation}

根据$n$是否为1可将回归问题分为一元回归和多元回归分析；根据$m$是否为1可将该问题分为简单回归分析和多响应回归分析；根据$\mathbf{F}$描述的关系类型可将该问题分为线性回归分析和非线性回归分析。

以多项式回归（Polynomial Regression，简单一元非线性回归模型）为例，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，因为任一函数都可以分段用多项式来逼近，同时其优点在于可以通过增加x的高次项对实测点进行逼近。公式\ref{eq:nonLinearRegression}描述一元$m$次多项式回归方程。

\begin{equation}
\label{eq:nonLinearRegression}
\hat{y} = b_0 + b_1x + b_2x^2 + \cdots + b_mx^m
\end{equation}

通过回归分析建立上述多项式回归模型的流程如下：利用给定规模为$n$的数据集$D={(x_1, y_1), \cdots, (x_n, y_n)}$（图\ref{Fig.regression}蓝色点表示）作为输入，通过最小化公式\ref{eq:nonLinearRegression2}中的目标函数$E$以得到方程\ref{eq:nonLinearRegression} 中的各参数$\{b_0, \cdots, b_m\}$，图\ref{Fig.regression}中红色曲线是由输入数据集拟合得到的，表示目标非线性回归方程（$m = 2, b_0 = 2, b_1 = 1, b_2 = 0.5$）。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_regression.png}}
	\caption{多项式回归模型.}
	\label{Fig.regression}
\end{figure}

\begin{equation}
\label{eq:nonLinearRegression2}
E=\Sigma^{n}_{i=1}f(\hat{y}_i - y_i)
\end{equation}

其中$\hat{y}_i$是$x_i$带入公式\ref{eq:nonLinearRegression}求得的计算值，$y_i$是数据集$D$中的观测值，$f$是计算计算值与观测值之间距离的函数。

\subsubsection{回归树}
%回归树是决策树\cite{}的子类，当决策树解决分类问题时又被称为分类树（classification tree）。

回归树\cite{Lewis2000CART}（regression tree）是用来解决回归问题的一种树状决策模型。类比任意函数可以利用分段多项式逼近其回归方程的思想，任意复杂的高维非线性回归问题可以通过一定的划分方式将一个复杂的函数表达式拆分为若干个较为简单的多项式表达，简单的多项式表达将极大地降低原始函数回归模型的构造成本。基于这样的启发，回归树的基本思想为：以当前所要研究的问题为起点，将自变量$X$的指定特征属性作为划分依据，自顶向下递归地完成当前问题域的划分，使得划分后的的子问题域所包含的信息尽可能少，这有利于子问题域的回归模拟，从而从整体上解决当前回归问题。常用的划分依据有基尼系数（Gini index）标准和信息增益（information gain）标准。

树状决策模型主要包括两种功能和意义的节点，分别为决策节点（非叶节点）和终端节点（叶子节点）。决策节点对应某个特征属性与对该属性的测试条件，该节点的分支路径则表示一种测试输出。每个终端节点包含属于同一子回归模型的数据值，当该回归模型简化到极限时，终端节点可以仅用某一数值用来描述对此类问题的回归结果。

图\ref{Fig.RegressionModel}以自变量$X$在二维空间、响应变量$Y$为一维变量为例，对回归树的构造及预测过程进行说明。图\ref{Fig.RegressionModel_a}中的圆点表示在$X$空间中采样得到的100条训练数据，$x_1, x_2$是$X$空间下的两个特征属性。回归树的构造过程是：根据一定的划分标准将空间$X$递归地划分为5个不相交的子空间$S_1, \cdot, S_5$，各子空间中包含部分训练数据，且假设各子空间的简单回归模型为：空间$S_i(1 \leq i \geq 5)$中样本的预测值$Y'$等于当前空间下所有训练样本响应值的平均，参见公式\ref{eq:RegressionSimple}：

\begin{equation}
\label{eq:RegressionSimple}
Y'=\frac{\sum^{|S_j|}_{i=1}Y_i}{|S_j|}, \ \forall Y_i \in S_j
\end{equation}

其中$|S_j|$表示空间$S_j$中包含训练数据的数量。图\ref{Fig.RegressionModel_b}是对应构建生成的回归树，回归树的预测过程是：当预测数据$x_1 = 0.301, x_2 = 0.812$进入到该回归树的根节点时，经过不同的决策节点以虚线所示的分支进入终端节点0.548，且0.548就是该预测数据的预测结果。

\begin{figure*}[!htb]
	\centering
	\subfigure{
		\includegraphics[scale=0.3]{figures/placeholder.jpg}
		\label{Fig.RegressionModel_a}
	}
	\subfigure{
		\includegraphics[scale=0.3]{figures/regressionModel_2.png}
		\label{Fig.RegressionModel_b}
	}
	\caption{(a) 数据输入空间. (b) 回归树模型.}
	\label{Fig.RegressionModel}
\end{figure*}

回归树模型其优点在于分析的过程更加贴近人脑的思考方式，模拟人类的决策过程使得划分结果易于解释，且在维度较低时能够高效地进行学习和预测。但其主要缺点在于回归树的预测稳定性严重依赖于参与训练的输入数据，即：泛化能力差。泛化能力是指：针对当前问题域下描述同一规律的新的数据，学习模型给出正确预测的能力。泛化能力差具体表现在：当输入的训练数据为问题空间欠采样结果时，对新数据的预测结果准确率低且稳定性差，其根本原因在于不同的欠采样训练数据构会直接影响到回归树本身的结构和决策标准；而当输入数据过采样时，有可能造成树节点的过度划分，导致过拟合现象，相应的划分结果也难以理解。

\subsubsection{回归森林完成回归分析}

\textbf{基本思想}

回归森林（regression forest）\cite{}是将若干回归树组合后形成的集成学习模型\cite{} ，它强调通过多个回归树的预测结果共同决定最终结果以提高学习模型的泛化能力。其理论依据基于Bagging （Bootstrap aggregating）\cite{}方法。

Breiman在1994年提出Bagging方法，该方法的意义在于进一步提高学习模型的稳定性以及预测效率。其基本思想是通过Bootstraping采样方法（均匀且有放回采样）从一个包含$n$条样本的训练数据集$D$中得到$m$个不同的、规模均为$n'$的训练子集，该训练子集也被称作bootstrap样本，作为对应回归树的输入数据进行回归树的独立构建，单个回归树被称为弱学习器，Breiman认为将这样的弱学习器进行聚合可以得到一个强学习器，并给出了详细的数学证明。

图\ref{Fig.regressionForest}展示了基于Bagging方法的回归森林基本结构以及具体的预测过程，该模型由$m$个相互独立的回归树$T_i, i \in [1, m]$组成：

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/regressionForest.png}}
	\caption{回归森林模型.}
	\label{Fig.regressionForest}
\end{figure}

如图\ref{Fig.regressionForest}所示，当对某条预测数据$X$的结果进行预测时，$X$会进入这$m$棵回归树，并分别得到相应的预测结果，记为$T_i(X)$。回归森林利用公式\ref{eq:AverageFunction}计算得到$X$最后的预测结果$\widehat{Y}$并输出。

\begin{equation}
\label{eq:AverageFunction}
\widehat{Y}=\frac{1}{m}\sum_{i=1}^{m}T_i(X)
\end{equation}

\textbf{泛化误差估计}

泛化误差估计是衡量学习模型泛化能力的量化标准，误差估计值越小表明模型的泛化能力越强。误差是指学习模型的预测值与输入数据真实值之间的差距，而泛化误差是一类特殊的误差，它特指未参与学习模型构建的数据集在该学习模型上产生的误差。

OOB（Out Of Bag）\cite{}误差估计用来衡量回归森林的泛化能力。接着上一节的讨论，通过Bootstraping采样方法得到的每个bootstrap样本$D_{sub}$大致覆盖数据集$D$ 三分之二的数据记录，而未覆盖到的数据集则被称为$D_{sub}$的OOB样本。从另一角度考虑，这说明数据集$D$中的任一数据记录$X_j, j \in [1, n]$不会被所有的bootstrap样本覆盖，假设有$k$ 个这样的数据集均为包含$X_j$，分别记$D_{sub}^1, D_{sub}^2, \cdot, D_{sub}^k$，由它们训练生成的回归树模型记为$T_{sub}^1, T_{sub}^2, \cdot, T_{sub}^k$，则该条数据$X_j$均为参与到上述回归模型的构建，则当前回归森林的OOB误差估计可由公式\ref{eq:calOOB}表示。

\begin{eqnarray}\label{eq:calOOB}
	OOB = \frac{1}{n}\sum_{j=1}^(n)E(Y^j - Y^{j'}) \nonumber \\
	Y^{j'} = \frac{1}{k}\sum_{i=1}^{k}T_{sub}^{i}(X^j)
\end{eqnarray}
其中$E$是误差衡量函数。

\textbf{变量重要性测量}

变量重要性（Variable Importance, VI）测量是回归森林衡量各特征属性重要程度的方法，变量此时指代$X$向量的各特征属性。其基本思想是：特征属性的重要程度与该特征属性影响预测结果的能力成正比。特征属性影响预测结果的能力具体表现在：如果仅当前特征属性的采样值结果发生一定程度的错误，回归森林产生预测失误的程度越大，则认为该特征属性影响预测结果的能力越大。

变量重要性的计算基于OOB误差估计，设函数$\mathbf{I}^D(\mathbf{p})$表示从数据集$D$ 的中结算得到特征属性$\mathbf{p}$的变量重要性，则$\mathbf{I}^D(\mathbf{p})$可由公式\ref{}计算得到，假设当前构建出的回归森林拥有$m$ 棵回归树。

\begin{equation}
\mathbf{I}^D(\mathbf{p}) = \frac{1}{m}\sum_{i=1}^{m}\mathbf{I}_i^D(\mathbf{p})
\end{equation}
其中$\mathbf{I}_i^D(\mathbf{p})$表示从所有回归树上计算得到的变量重要性。

定义操作符$\mu(D,\mathbf{p})$，通过执行该操作，可以完成数据集$D$的转换以生成一组新数据$D'$。其转换规则是：随机均匀扰乱数据$D$中$\mathbf{p}$特征属性列的采样值，其余特征属性值保持不变。

以\ref{eq:MutationOperator}为例，假设数据集$D$是一组包含有4条记录的数据集，则每列$[v_{1j}\ v_{2j}\ v_{3j}\ v_{4j}]^T$\\ 是特征属性$p_j(1 \leq j \leq 3)$的采样值，假设进过一次$\mu(D,\mathbf{p_2})$操作，则可能生成\ref{eq:MutationOperator}所示的新数据集$D'$。

\begin{equation}
\label{eq:MutationOperator}
D =
\left[ \begin{array}{cccc} x_{11} & x_{12} & x_{13} & y_1 \\\cdots & x_{22} & \cdots & \cdots  \\\cdots & x_{32} & \cdots & \cdots \\x_{41} & x_{42} & x_{43} & y_4 \end{array} \right ]\Longrightarrow D' =
\left[ \begin{array}{cccc} x_{11} & x_{22} & x_{13} & y_1 \\\cdots & x_{42} & \cdots & \cdots \\\cdots & x_{12} & \cdots & \cdots \\x_{41} & x_{32} & x_{43} & y_4 \end{array} \right ]
\end{equation}

计算$\mathbf{I}_i^D(\mathbf{p})$的基本原理是计算扰乱前后两组数据分别在当前回归树$T_i$上其均方误差（mean squared error, MSE）的绝对差值，公式参见\ref{eq:VI_tree}。

\begin{equation}
\label{eq:VI_tree}
\mathbf{I}^{\mathcal{D}}_i(\mathbf{p})=\left|E(\mathcal{O}_{i}^\mathcal{D})-E(\widetilde{\mathcal{O}}_{i}^\mathcal{D})\right|
\end{equation}
其中$\widetilde{\mathcal{O}}_{i}^D = \mu(\mathcal{O}_{i}^D,\mathbf{p})$ 是由数据集$\mathcal{O}_{i}^D$在特征属性$\mathbf{p}$上经过扰乱操作得到的新数据集。$E(\mathcal{S})$表示来自数据集$\mathcal{S}$的均方误差。假设任一数据记录$s_k\in\mathcal{S}$，$s_k.\mathbf{x}$和$s_k.y$分别为该记录的自变量和响应变量，则$E(\mathcal{S})$可由公式\ref{eq:MSE}表示：

\begin{equation}
\label{eq:MSE}
E(\mathcal{S})=\frac{\sum\limits_{s_k\in\mathcal{S}}(s_k.t-T_i(s_k.\mathbf{x}))^2}{|\mathcal{S}|}
\end{equation}
同时，数据集$\mathcal{O}_{i}^\mathcal{D}$实际是基于OOB误差估计原理的“袋外数据”，它是未参与创建回归树$T_i$的数据的集合，此时$E(\mathcal{O}_{i}^\mathcal{D})$为回归树$T_i$提供其泛化误差的评估标准。如果特征属性$\mathbf{p}$对回归树$T_i$预测准确性的影响较小，则此时$E(\mathcal{O}_{i}^\mathcal{D})$ 与$E(\widetilde{\mathcal{O}}_{i}^\mathcal{D})$差值较小，即$\mathbf{I}^{\mathcal{D}}_i(\mathbf{p})$结果值较小。

\subsection{OpenMP并行加速技术}

Open Multi-Processing\cite{8434208}（OpenMP）技术是用于共享内存并行系统的编程处理方案，OpenMP 技术充分利用多处理器架构，对并行算法进行高度抽象，自动完成程序编译阶段的并行化处理。

OpenMP技术支持多语言编程以及跨平台移植。语言方面支持Fortran、C 语言和C++，操作系统包括Windows、macOS以及Linux系统等，在编译器方面，兼容常见的Sun Compiler，GNU Compiler和Intel Compiler等。

OpenMP技术具有良好的可编程性。它为开发者提供一套可扩展的编程接口，在保证一些共享数据同步互斥的前提下，开发者仅需要将并行指令添加到相应需要进行并行加速部分即可完成并行加速，而无需关心并行计算的具体实现细节。相对于传统多线程程序设计中线程粒度、负载平衡等并行化难题，OpenMP库给出良好的解决方案并完成不同并行系统下的配置。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/OpenMP.png}}
	\caption{Fork-join模型.}
	\label{Fig.OpenMP}
\end{figure}

OpenMP的执行原理采用“Fork-join模型”的执行流程。以图\ref{Fig.OpenMP}为例，当一个多线程并行程序开始启动时，操作系统为该程序分配一个主线程，主线程执行串行计算直到遇到OpenMP 标记的并行区域时，主线程通过Fork操作完成线程的划分已形成若干个分支线程，同时当前的计算任务也被相应划分为若干子任务并被分配到不同的分支线程，而分支线程则并行执行不同的子任务，当最后一个分支线程完成其子任务后，通过join操作将线程合并回主线程，并将各子任务的执行结果反馈给主线程，由主线程完成最终结果的合并工作。



%\subsection{贪心算法}

\section{基于特征空间划分的算法级绘制性能瓶颈识别}
\label{sec:CoreAlgorithm}

本章主要对基于特征空间划分的算法级绘制性能瓶颈识别技术进行了详细的介绍分析。首先，提出基于瓶颈分析树进行特征空间划分的基本思想，然后进一步阐述本文两种不同的实现方案，包括贪心策略与类遗传策略。在详细分析贪心策略的瓶颈分析树构建过程在识别绘制性能瓶颈过程中出现的问题以及产生问题的根本原因之后，讨论了类遗传策略解决上述难点的理论依据与基本思想；第三步，重点讨论本文基于类遗传策略的性能瓶颈识别技术需要解决的关键问题；第四步，针对关键问题详细阐述了算法的具体实现流程与相关实现细节；最后对本章进行简要总结。

\subsection{算法概述}

\subsubsection{瓶颈分析树}

本文核心算法提出的目的是为了解决在完整性能数据集上无法确定全局性能瓶颈的情况。其基本思想是：通过特征超平面对数据所在的特征空间进行划分，使得原始性能数据集被划分到了不同的子特征空间形成子数据集，由于超平面划分可能进一步简化子数据空间中“特征”与“结果”影响关系，从而提高“局部性能瓶颈”确定工作的可能性。

为了进一步解释上述思想，本文将该瓶颈识别问题与\cite{Cooper2011Happiness} 研究中寻找最影响人类幸福指数因素的情景进行类比。在对人类幸福感的研究中，研究者提出：事实上很难找到一个普适性的决定因素影响人类幸福感，因为从整体上来看，众多因素（例如性别、宗教、健康状况、收入等）均会影响到人类幸福感的判定，而这些因素影响的程度可能不会有明显差异。但是假设按照人类的年龄段这一特征将人类进行划分时，可能很容易确定出影响人幸福感的决定性因素。C.Cooper 等人在其研究\cite{Cooper2011Happiness}中指出：亲密关系和好友的数量是影响16-59岁人群其幸福感的最重要因素，而婚姻对60-79 岁人群的幸福感影响最大，对于79 岁以上的人群而言，最重要的影响因素是参加宗教活动的频率。

瓶颈分析树是对特征空间划分过程以及数据集划分结果的表示，构建瓶颈分析树的过程就是完成本文核心算法的过程。在具体阐述瓶颈分析树之前，简要回顾一些基本概念。本文延续采用文章\cite{Zhang:2018:AIP:3208159.3208178} 的随机森林模型构建绘制性能模型。

假设一个包含有$M$个绘制算法(记为：$A_1, A_2, ..., A_M$) 的复杂绘制系统$\mathfrak{R}$，其中每个算法$A_i$($i=1, 2, ..., M$)包含有若干个影响绘制性能的算法级参数($\mathbf{p}_i^1, \mathbf{p}_i^2, ...$)。 所有这些包含于$\mathfrak{R}$ 的算法级参数(假设有N 个)构成当前研究问题域的\textbf{参数集}，记为：$\mathbf{P}=\{\mathbf{p}_1, \mathbf{p}_2, ..., \mathbf{p}_N\}$。 假设任意算法级参数$\mathbf{p}_i\in \mathbf{P}$拥有其有效取值的集合$\mathbf{V}(\mathbf{p}_i)$，则有\textbf{参数空间}：$\mathbb{P}=\{\mathbf{V}(\mathbf{p}_1)\times \mathbf{V}(\mathbf{p}_2)\times ... \times \mathbf{V}(\mathbf{p}_N)\}$，该参数空间包含参数集$\mathbf{P}$所有参数$\mathbf{p}_i$ 其有效取值所有可能的组合。

\cite{Zhang:2018:AIP:3208159.3208178} 提出采用随机森林\cite{Breiman2001Random} 构建描述参数集$(\mathbf{p}_1, \mathbf{p}_2, ..., \mathbf{p}_N)$ 与绘制时间$t$ 之间非线性关系的估计模型$\mathcal{F}(\mathbf{p}_1, \mathbf{p}_2, ..., \mathbf{p}_N)=t$。 基于随机森林，性能瓶颈的识别工作可以转化为算法级参数$\mathbf{p}_i$ 对响应变量$t$ 的\textbf{变量重要性}(Variable importance, VI) 测量工作\cite{Chang2008Feature}\cite{Gr2015Variable}。 变量重要性方程$\mathbf{I}(\mathbf{p})$ 用来计算参数$p$ 的VI得分$s_\mathbf{p}$，以定量测量参数$\mathbf{p}$ 对$t$的影响程度。

\begin{figure*}[!htb]
	\centering
	\subfigure{
		\includegraphics[scale=0.13]{figures/Figure1_a.png}
		\label{Fig.BasicIdea_a}
	}
	\subfigure{
		\includegraphics[scale=0.13]{figures/Figure1_b.png}
		\label{Fig.BasicIdea_b}
	}
	\subfigure{
		\includegraphics[scale=0.13]{figures/Figure1_c.png}
		\label{Fig.BasicIdea_c}
	}
	\caption{识别瓶颈的基本思想. (a) $\mathbf{\tilde{p}}_1$和$\mathbf{\tilde{p}}_2$ 被识别为瓶颈. (b) $\mathbf{\tilde{p}}_1$和$\mathbf{\tilde{p}}_2$不是瓶颈，原因是$\mathbf{\tilde{p}}_2$ 与$\mathbf{\tilde{p}}_3$ 的落差值小于阈值. (c) $\mathbf{\tilde{p}}_1$, $\mathbf{\tilde{p}}_2$, $\mathbf{\tilde{p}}_3$, $\mathbf{\tilde{p}}_4$ 均不是瓶颈，原因是它们的个数总和超出了限定阈值.}
	\label{Fig.BasicIdea}
\end{figure*}

一旦每个算法级参数的VI得分被计算出来，所有参数根据其VI值按降序排序，降序后的参数集记为：$(\mathbf{\widetilde{p}}_1, \mathbf{\widetilde{p}}_2, ..., \mathbf{\widetilde{p}}_N)$，之后，性能瓶颈集可以按照如下方式完成定义。如图\ref{Fig.BasicIdea}所示，假设VI 得分的最大落差存在于$\mathbf{\widetilde{p}}_i$ 和$\mathbf{\widetilde{p}}_{i+1}$之间（例如图\ref{Fig.BasicIdea_a}中的$\mathbf{\widetilde{p}}_2$和$\mathbf{\widetilde{p}}_3$，图\ref{Fig.BasicIdea_c} 中的$\mathbf{\widetilde{p}}_4$和$\mathbf{\widetilde{p}}_5$）则前$i$ 个参数如果满足公式\ref{eq:bottleneck}，则称这$i$ 个参数为性能瓶颈：

\begin{eqnarray}\label{eq:bottleneck}
	i<\epsilon_1 \nonumber \\
	s_{\mathbf{\tilde{p}}_i}-s_{\mathbf{\tilde{p}}_{i+1}}>\epsilon_2
\end{eqnarray}
其中$\epsilon_1$和$\epsilon_2$是用户定义的阈值.

实际上，根据公式(\ref{eq:bottleneck}) 的定义并不能保证非空的瓶颈集一定存在。图\ref{Fig.BasicIdea_b} 描述了这样一种情况：当各参数的VI 得分不存在明显最大落差时，这意味着所有参数对系统绘制效率的影响不存在明显差异；而图\ref{Fig.BasicIdea_c}则展示了另一种瓶颈识别失败的情形：数量过多的参数均对系统绘制性能造成明显影响，这时依然无法确认绘制系统的性能瓶颈是什么。

本文划分性能数据集的工作流程如下：

\begin{itemize}
    \item 预采集得到一组\textbf{性能数据集}$\mathcal{P}=\{(p_1^i, p_2^i, ..., p_N^i, t_i)\}$，其中$(p_1^i, p_2^i, ..., p_N^i)$ 是当前参数空间$\mathbb{P}$ 下的一次有效取值，$t_i$ 则是在当前有效取值$(p_1^i, p_2^i, ..., p_N^i)$ 下测量得到的相应绘制时间。换言之，性能数据集$\{(p_1^i, p_2^i, ..., p_N^i, t_i)\}$ 可以被视为当前参数空间$\mathbb{P}$ 以及绘制系统$\mathfrak{R}$ 下的一次采样；

	\item 构建随机森林以评估算法级参数（参数集$\mathbf{P}$）与绘制性能（绘制时间$t$）之间的非线性关系模型；

    \item 根据不同策略（具体参见\ref{sec:genBAT}、\ref{sec:genBATga} 小节）选取特征超平面将采样得到的性能数据集$\mathcal{P}$ 划分到若干个子数据集，保证在每个子数据集中均可利用上述同样的基于变量重要性的方法找到该子数据集下的局部性能瓶颈；

\end{itemize}

在具体构建瓶颈分析树时，本文采用算法\cite{Zhang:2018:AIP:3208159.3208178} 中提出的：利用特征超平面思想完成分析树的构建，得到的瓶颈分析树本质上是二叉树。其生成过程为：根据当前绘制系统的复杂程度确定瓶颈分析树的最大树深，记为$D_M$，将预采集的完整性能数据集作为瓶颈分析树的根节点数据，并以此作为起始，完全随机地选择划分特征（参数集$\mathbf{P}$ 中的任意参数$\mathbf{p}_i$）和划分点（参数$\mathbf{p}_i$对应有效取值$p_i^j$），划分得到两个左右子节点尝试确定是否满足终止条件，如果满足，即：其节点深度达到$D_M$ 或者其局部空间内找到瓶颈，则终止进一步划分，否则继续子节点的划分过程。%终止条件为：在当前子节点中找到局部性能瓶颈或已达到划分最大树深亦或当前子节点拥有的数据量不可以进一步进行划分。

\subsubsection{贪心策略构建瓶颈分析树}
\label{sec:genBAT}

\textbf{问题描述}

基于上述未优化的瓶颈分析树生成过程极其容易得到划分形态不好的瓶颈分析树。划分形态的优劣主要体现在以下两个方面：

\begin{itemize}
    \item 瓶颈分析树叶子节点的局部性能瓶颈中，参数的个数偏大，更趋向于用户指定的阈值，这不利于开发过程中的优化，因为优化过程期望性能瓶颈中涉及到的算法级参数越少越好。如图\ref{Fig.BadTree01} 所示，用户期望每个局部的瓶颈至多为2 个，对于图\ref{Fig.BadTree01_a} 来说，当前的划分平面$H$ 导致叶子节点$D$ 的性能瓶颈有2 个，而\ref{Fig.BadTree01_b} 中，选取另一个划分平面$H^{'}$ 进行数据划分后，叶子节点$D$ 的性能瓶颈仅有1 个；

    \item 瓶颈分析树非叶节点在进行数据划分时，其左右子节点数据量的极度不平衡导致分析树的某一侧健壮，而另一侧迅速萎缩，事实证明这并不利于进一步探索局部性能瓶颈。如图\ref{Fig.BadTree02_a} 所示，节点$B$ 包含6000个采样数据量，即使当前节点无法确定出局部瓶颈，但将其继续划分，其任意子节点拥有的数据量必然小于预先设定的阈值5000，因此划分失败，这成为枝干的萎缩。而枝干萎缩的情况出现越多，则当前二叉树形态越差，极端情况下会出现数量巨大的萎缩节点，这不利于确定局部性能瓶颈。而\ref{Fig.BadTree02_b} 中，该瓶颈分析树的各个枝干较为平衡，其叶子节点总个数为4 个，而每个叶子节点均可以确定其局部性能瓶颈，这被认为是形态好的分析树。
\end{itemize}

\begin{figure*}[!htb]
	\centering
	\subfigure{
		\includegraphics[scale=0.16]{figures/BAT_bad_01_a.png}
		\label{Fig.BadTree01_a}
	}
	\subfigure{
		\includegraphics[scale=0.16]{figures/BAT_bad_01_b.png}
		\label{Fig.BadTree01_b}
	}
	\caption{不同划分结果一. (a) 该叶子节点内需要优化的参数有两个：$p_1, p_2$. (b) 该叶子节点内需要优化的参数有一个：$p_1$.}
	\label{Fig.BadTree01}
\end{figure*}

\begin{figure*}[!htb]
	\centering
	\subfigure{
		\includegraphics[scale=0.16]{figures/BAT_bad_02_a.png}
		\label{Fig.BadTree02_a}
	}
	\subfigure{
		\includegraphics[scale=0.16]{figures/BAT_bad_02_b.png}
		\label{Fig.BadTree02_b}
	}
	\caption{不同划分结果二. (a) 该瓶颈分析树左端健壮，右端萎缩. (b) 该瓶颈分析树枝干平衡.}
	\label{Fig.BadTree02}
\end{figure*}

\textbf{原因分析}

上述原始的瓶颈分析树生成过程很容易得到划分形态不好的瓶颈分析树，其根本原因在于对划分超平面（划分特征和划分点）的全随机选择。这种方式不考虑选取的划分超平面对划分结果的影响，包括划分后子空间各自拥有的数据量、以及子空间是否可以确定出局部性能瓶颈，而这些均对瓶颈分析树的生成起指导性作用。

\textbf{贪心策略}

本文基于贪心策略构建瓶颈分析树，充分考虑划分平面对空间划分结果的影响，利用贪心策略为划分超平面的选取制定标准，该标准指出：选取划分特征以及对应划分点，应尽可能使得当前节点划分得到的子节点能够尽可能确定出局部性能瓶颈（瓶颈个数越少越好）且左右子节点的数据量不出现严重失衡。

充分考虑到上述两点因素，本课题提出基于贪心策略构建瓶颈分析树。其实现过程为：将当前数据集所在的节点作为研究节点，计算该节点各参数的变量重要性数值，若根据变量重要性并结合公式\ref{eq:bottleneck}能够分析出性能瓶颈，则结束整个流程。否则，遍历当前节点所有可能的划分超平面$\mathcal{H}$，利用本文提出的对超平面划分结果进行评估的评估函数$\mathfrak{S}(\mathcal{H})$完成对该划分超平面的分数评估，从中选取$\mathfrak{S}(\mathcal{H})$得分最高的划分分超平面作为当前节点最佳划分策略。重复上述过程，直到所有节点均找到局部性能瓶颈。其中$\mathfrak{S}(\mathcal{H})$充分考虑划分后左右子节点中重要参数的个数以及左右子节点内数据量平衡与否。重要参数的个数就是公式\ref{eq:bottleneck}中的$i$。

\begin{equation}
\label{eq:BestSplitPlane}
\mathfrak{S}(\mathcal{H})=s(\mathcal{D}^L_\kappa)+s(\mathcal{D}^R_\kappa)
\end{equation}
其中，$\mathcal{D}^L_\kappa$和$\mathcal{D}^R_\kappa$是当前节点数据集$\mathcal{D}_\kappa$划分成的两个子数据集。而得分方程$s(\mathcal{D}_\kappa)$ 又被定义为如下形式：

\begin{equation}\label{eq:EvaluationScore}
s(\mathcal{D}_\kappa) =
  \left \{
   \begin{array}{lcl}
   1.0&      & {\mathbf{P}_B^{\mathcal{D}_{\kappa}} \neq \emptyset}\\
   \frac{\sum\limits_{i=1}^b\mathbf{I}^{\mathcal{D}_\kappa}(\mathbf{p}'_i)}{\sum\limits_{i=1}^N\mathbf{I}^{\mathcal{D}_\kappa}(\mathbf{p}'_i)}&      & {\mathbf{P}_B^{\mathcal{D}_{\kappa}} = \emptyset}\\
   \end{array}
   \right.
\end{equation}
其中$\mathbf{I}^{\mathcal{D}_\kappa}(\mathbf{p}'_i)$表示当前各参数变量重要性数值按降序排列之后第$i^{th}$大的变量重要性数值，$b$表示变量重要性最大落差值之前参数的个数，$N$表示参数总个数，$\mathbf{P}_B^{\mathcal{D}_{\kappa}}$ 表示在数据$\mathcal{D}_{\kappa}$下的性能瓶颈集合，该集合有可能为空当不满足公式\ref{eq:bottleneck}时。

\subsubsection{类遗传策略构建瓶颈分析树}
\label{sec:genBATga}

通过上一节对基于贪心策略构建瓶颈分析树其基本原理的介绍以及对其基本流程的再现实验，我们发现上述策略在性能识别过程中存在以下两个重要的问题：

\textbf{问题描述}

基于贪心策略构建瓶颈分析树，在其构建分析树时并没有一种寻找全局最优算法倾向，其划分结果往往不一定具备好的指导结果。具体来说，贪心策略构建瓶颈分析树，在选择划分点将当前数据空间划分为两个子空间时，总是选择使得两个子空间中占据重要变量的参数个数之和最少的划分点，并重复该过程直到在子空间找到局部性能瓶颈或子空间不可继续再被划分，这是局部最优解。实验表明，以贪心方式构建的瓶颈分析树总是无法找到更好的瓶颈分析树。

\textbf{原因分析}

该问题产生的根本原因在于：绘制性能数据的划分过程并不一定具备最优子结构性质，它跟所采集场景的复杂程度有关，最优子结构性质保证问题的最优解包含子问题的最优解，但当绘制场景的复杂度进一步增加时，往往无法保证最优子结构特性，因而利用贪心策略构建瓶颈分析树无法找到更优解。

\textbf{问题描述}

基于贪心策略构建瓶颈分析树产生的第二个问题是构建的瓶颈分析树形态不稳定，即：重复瓶颈分析过程，得到的特征空间划分结果以及对应的识别到的瓶颈可能会不稳定。具体来说，在特征空间划分的过程中，存在若干方案满足目标划分结果，贪心策略对其任一划分结果完成评估，并总是在这些划分结果中选取得分最高的一个方案作为最终结果。事实上，这些方案的评分结果会出现合理浮动，这将导致得分最高的划分方案并不总稳定在某一种划分结果上，这导致该策略最终确定的方案其瓶颈分析树形态不稳定。

\textbf{原因分析}

造成这一问题的根本原因在于贪心策略对多个划分方案的非统计性选择以及潜在瓶颈（算法级绘制参数）变量重要性其计算数值的合理浮动，即：\textbf{误差内浮动}。变量重要性计算数值的误差内浮动是指：在预采集性能数据集一定，构建的随机森林性能评估模型稳定的前提下，根据评估模型下变量重要性计算原理计算得到的某参数变量重要性数值会在误差范围内上下浮动。当各参数对绘制性能的影响力相差较大时，其数值在误差范围内的浮动并不会影响瓶颈分析树的构建过程，但当各参数对绘制性能的影响力相差接近时，此时数值的浮动将直接影响到划分点的选取从而进一步影响瓶颈分析树的形态，因此有可能会得到若干个整体评估分数相近，但形态不同的瓶颈分析树。同时，又由于评估瓶颈分析树时，再次用到了该树各个叶子节点中各参数的变量重要性计算结果，这就导致这些性能瓶颈分析树的评估值出现浮动，最终导致贪心策略结果的不稳定性。

\textbf{类遗传策略}

本文提出的基于类遗传策略的瓶颈识别算法可以解决上述问题。该算法摒弃上述选择瓶颈分析树的方式，其基本思想是：将某种特征空间划分方案（具体表现为一个瓶颈分析树）抽象为一个生物个体，选取一定基数的生物个体构成一个完整的生物种群，该种群作为潜在最优解的问题解集，从该初始种群开始，选择适应度（参见章节\ref{sec:FitnessCalculate}）更高的生物个体作为父类，模拟遗传学机理的生物进化过程，借助自然遗传学的遗传算子（参见章节\ref{sec:GAOperator}）生成新的子类个体，再根据达尔文生物进化论的自然选择算子（参见章节\ref{sec:GAOperatorSelector}），不断筛选出适应度更高的生物个体进行保留，而淘汰适应度低的个体，并通过自然遗传学中的变异算子（参见章节\ref{sec:GAOperatorMutex}）保证种群的突变性和多样性，防止过早收敛于局部最优解的情况出现。以此循环完成种群的迭代，直至种群中所有个体的适应能力趋于收敛。整个过程将导致种群像自然进化一样，后代种群比前代更加适应于环境，末代种群中的统计得到的最优个体就是本文问题的近似最优解。

本文基于类遗传策略构建瓶颈分析树需要解决的关键问题是：

\begin{itemize}
	\item 初始种群规模在理想条件下应包含本文算法问题的所有解，但这样的种群规模对于计算效率和计算资源的占用是不切实际的，因此，如何保证在种群规模一定、尽可能在保证初始种群多样性和随机性的前提下，在所有问题解中选取一定规模的解集合作为初始种群，以满足加快种群寻找最优解进程的目标。换言之，如何保证初始种群个体多样性和随机性的同时，生成适应度较高的初始种群；
	\item 如何将不同的特征空间划分方案进行抽象，使得遗传算法的各个算子能够作用于划分方案的筛选和进化。类似自然界中遗传学的作用原理：交叉遗传算子并不直接作用于生物个体，而是通过生物个体的染色体进行优秀基因的交叉与保留的，本文将特征空间的划分方案作为遗传个体，则需要对划分方案进行抽象，抽象出能够唯一表示该个体的染色体序列，该过程的核心难点在于：瓶颈分析树个体的形态差异巨大，制定的染色体编码标准必须使得生成的染色体能够顺利地完成基因序列的等位交叉、重组；
    \item 设计合理的适应度函数以指导初始种群朝着预期目标方向进化收敛。个体适应度的评估在整个遗传算法中起到决定性作用，包括种群的收敛方向与收敛速度。因此，如何设计合理的个体适应度函数能够使得末代种群中的个体满足对最优解的要求也是本文重点需要解决的问题；
\end{itemize}

为解决上述关键问题，本文算法采用如下流程完成类遗传策略构建瓶颈分析树，核心部分包括创建初始种群、编码种群中的个体、构建适应度评估标准、进行遗传学交叉、选择、变异算子的操作完成新一代种群的生成，迭代此过程直至满足结束条件。本文算法实现流程如图\ref{Fig.flowchart_ga}所示：

\begin{figure}[!h]
	\centering{
	\includegraphics[width=.5\linewidth]{figures/FlowChart_ga.png}}
	\caption{类遗传策略整体流程图.}
	\label{Fig.flowchart_ga}
\end{figure}

图\ref{Fig.flowchart_ga}描述了伪遗传策略识别局部性能瓶颈算法的各个阶段。第一阶段完成规模为$N$ 的初始种群生成工作，其中$N$ 是一个预设的值，其具体数值根据当前问问题域的规模大小决定；初始种群的生成细节参见\ref{sec:GenInitialPopulation}；第二阶段完成中群内所有个体的编码工作，编码工作为每个生物个体生成唯一标识的染色体，该染色体成为交叉算子的具体载体；第三阶段，利用适应度函数评估生物个体对环境的适应能力，适应度值越高的个体表示其生存能力越强，被淘汰的几率越小，同时也间接说明其染色体中存在更优秀的基因片段；第四阶段，根据上一阶段个体适应度的评估结果，选择出一定比例的个体作为进行交叉算子的父类，父类集合不重复两两随机配对完成交叉生成新的$n$ 个染色体；第五阶段，根据新的n 个染色体完成解码，重新恢复出n 个新的个体，并完成新个体适应度的计算；第六阶段，在新旧个体共同构成的临时种群中完成选择算子，即：具有更高适应度值的个体有更大的几率存活下来，此筛选过程采用轮盘赌的方式进行，并最终淘汰$n$ 个个体，留下规模仍为$N$ 的个体；第七阶段，在当前种群中根据一定的变异率完成种群个体的变异过程以保证一定的随机性和多样性，防止过快收敛，此时得到的种群即为新一代种群；第八阶段完成迭代终止条件的判断，如果相邻两代种群的个体平均适应度差值小于预设阈值则进入第九阶段，否则继续转入第二阶段；第九阶段，与前文算法相比，我们不再关注单个瓶颈分析树的优劣，最终在末代种群中，统计分析适应度最高且出现次数最多的个体作为最终最优解输出，以此避免由于变量重要性计算的浮动造成的决策偏差。

\subsection{生成初始种群}
\label{sec:GenInitialPopulation}

\subsubsection{基本目标}

本文算法需要解决的第一个关键问题就是初始种群的生成。初始种群由一定规模的瓶颈分析树共同构成。瓶颈分析树的生成方式以及分析树规模共同决定一个初始种群的质量，而初始种群的质量将直接影响本文核心算法的结果。其原因在于：根据\ref{sec:genBATga} 章所述，本文关注的问题属于NP问题，由于该问题的规模已经超出计算机在期望时间内决策的规模，因此不可能穷尽所有可能性，生成包含所有解的初始种群。相反，本文需要解决的问题是：在种群规模一定、保证初始种群多样性和随机性的前提下，在完整解集中，选取一定规模的解集合作为初始种群，以满足加快种群寻找最优解进程的目标。换言之，生成初始种群的基本目标是：如何保证初始种群个体多样性和随机性的同时，生成适应度较高的初始种群。

在提出本文生成初始种群算法前，首先回顾某个原始瓶颈分析树的生成过程：根据当前绘制系统的复杂程度确定瓶颈分析树的最大树深，记为$D_M$，将预采集的完整性能数据集作为瓶颈分析树的根节点数据，并以此作为起始，完全随机地选择划分特征和划分点，划分得到两个左右子节点尝试确定是否满足终止条件，如果满足，即：其节点深度达到$D_M$或者其局部空间内找到瓶颈，则终止进一步划分，否则继续子节点的划分过程。$N$ 个原始瓶颈分析树共同构成的初始种群被称为全随机初始种群。

分析全随机生成初始种群出现的问题：上述未优化的瓶颈分析树生成过程很容易得到划分方式不好的瓶颈分析树，其根本原因在于对划分特征的全随机选择。在这种方式下，当规模一定时，生成的瓶颈分析树很难涵盖完整解集中更多潜在的优质解，这将导致初始种群的个体适应度普遍偏低，因此直接导致整个遗传算法需要更多迭代次数以达到收敛，放缓了迭代速度。

除此之外，划分点的全随机选择也是另一个使得初始种群个体质量差的原因。划分点的完全随机选取有可能造成划分的左右子节点内数据量的严重不平衡，而变量重要性计算原理要求：提供变量重要性计算的数据量小于一定阈值时，变量重要性的计算结果将不再保证稳定性和正确性，这实际上造成了当前的瓶颈分析树是不合格的种群个体。实验2 关于变量重要性计算稳定性的实验给出了进一步验证和阈值的确认工作。

因此，为实现初始种群生成的基本目标，本文算法需要完成两点优化：划分特征的选择和划分点的选择。

\subsubsection{划分特征选择的优化}
\label{sec:SpliteFeature}

优化划分特征选择依据越重要的特征越应该被提前选为空间划分参数的原理改进了初代种群个体生成过程。具体来说，本文在随机选择非叶节点的划分特征时，使用当前非叶节点所有特征变量重要性数值作为权重，并以此进行轮盘赌选择：重要性越高的特征被选中为划分特征的概率越大。改优化方法强调：并不是重要性越高的特征就一定会被选择成为划分特征，通过轮盘赌的方式能够保证初始种群生成的随机性，防止过早收敛于局部最优解。

\subsubsection{划分点选择的优化}

为避免节点划分严重不平衡的情况出现，本文采用基于正态分布的轮盘赌算法进行划分点的选取。在完成\ref{sec:SpliteFeature} 的基础上，遍历被选中划分特征$\mathbf{p}$ 的在当前节点的所有有效取值（对于有效取值为连续变量得划分特征$\mathbf{p}$，间隔一定步长选取有效取值）作为划分点候选集合。以此遍历候选集合中的有效取值$v_p$，并以$v_p$ 作为划分点将当前节点中的数据集划分为左右两部分，左右两部分包含的数据量分别记为$D_L$，$D_R$，通过公式\ref{eq:ImbalanceCoefficient} 计算出以当前有效取值$v_p$为划分点进行节点划分时的失衡系数$\phi$：

\begin{equation} \label{eq:ImbalanceCoefficient}
    \phi=\frac{2\delta(D_L-D_R)}{D_T(1.0-2P_{D_{min}})}
\end{equation}

其中，$\delta$是下面正态分布公式\ref{eq:NormalDistribute} 中的标准差参数，$D_T$ 是当前节点持有的总数据量，$D_L$、$D_R$ 分别是划分后两部分含有的数据量，而$P_{D_{min}}$是由用户根据计算变量重要性需要的最少数据量确定的数据量最小阈值比例。

将该失衡系数$\phi(v)$作为自变量，按照如下正态分布公式\ref{eq:NormalDistribute}，可以计算出当前有效取值$v$作为最终划分点的概率：

\begin{equation} \label{eq:NormalDistribute}
    f(\phi)=\frac{1}{\sqrt{2\pi}\delta}e^{-\frac{\phi^2}{2\delta^2}}
\end{equation}

其中，$e$是自然指数，本文$\delta$取4.0，正态分布如图\ref{Fig.normalDistribute} 所示：

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/normalDistribute.png}}
	\caption{概率服从的正态分布.}
	\label{Fig.normalDistribute}
\end{figure}

所有有效取值被选中的概率作为轮盘赌的权重进行最终划分点的确定。本文通过该过程使得那些更有能力将数据划分更均衡的有效取值有更大几率成为划分点，从而尽可能防止数据的失衡划分。

\subsection{个体编码与解码}

\subsubsection{基本目标}

本文算法核心是完成对不同划分空间方案的统一编码抽象得到染色体，为遗传算子的实施提供具体载体，同时也需要完成根据染色体编码方式解码恢复出对应的空间划分方案，为适应度计算提供输入。

\subsubsection{编码}
\label{sec:Coding}

在阐述具体编码过程之前，需要明确进行统一编码的必要性，具体包括以下两点：

\begin{itemize}
    \item 本文算法所使用的染色体与个体一一对应，该染色体是个体的唯一标识。  本文的个体类似自然界一倍体生物[\ref{}]，每个个体只仅拥有一个染色体组，且该染色体组中仅有一种类型的染色体，而不像绝大多数二倍体生物其每个个体拥有一对染色体组。这表明本文不采用生物有性繁殖其DNA双螺旋其解旋和重新组旋[\ref{}] 的过程，而假设单个染色体仅包含一条单链DNA。

    \item 遗传算子的交叉算子实际上是不同两个个体间等长的单链DNA 中等位基因之间的交换过程，详细过程参见3.5 章关于遗传算子的阐述。因此，本文算法要求能够对不同空间划分方案也就是不同形态的瓶颈分析树完成统一形态的编码，使得染色体之间能够顺利进行等位基因之间的交换操作。
\end{itemize}

进行编码最直接的想法是对空间划分结果本身：即划分得到的子空间进行编码以满足唯一标识该划分结果，但该编码方式的难点集中在如下两点：

\begin{itemize}
    \item 针对某一性能采样数据集所在的特征数据空间，划分方案有无穷多种。
    \item 同时，每种方案得到的子空间并不一定相同。
\end{itemize}

为了具体说明上述问题，图\ref{Fig.3_2} 和图\ref{Fig.3_3} 给出了特征空间仅包含两个特征（二维情况下）的简单解释。图中，$p_1$，$p_2$表示当前影响绘制时间t 的特征属性，并且在该情况下仅有这两个特征会影响到绘制时间$t$，因此该问题的特征空间仅为一个二维空间。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_2.png}}
	\caption{划分子空间个数相同，划分方式不同.}
	\label{Fig.3_2}
\end{figure}

图\ref{Fig.3_2}(a)(b)中，均通过三次划分将原始数据空间划分为了4个子数据空间。红线表示第一次划分操作，图\ref{Fig.3_2}(a) 显示其首次划分选取了$p_1$ 作为划分特征、$v_2$ 作为划分点，图\ref{Fig.3_2}(b) 则显示其首次划分选取了$p_2$作为划分特征、$v_3$ 作为划分点进行。以此类推，蓝线和绿线分别表示第二次、第三次的划分操作，由图可知，图\ref{Fig.3_2}(a)和(b)在第二次和第三次划分时选取的划分特征和划分点并不一致，这造成了两种截然不同的划分方案。这表明即使特征空间仅包含两维特征，由于划分特征的先后顺序不相同、划分点取值不相同，对应得到的空间划分结果其数量也是十分庞大的。当研的特征空间维度逐渐增大时，这种情况的复杂度会呈现指数级的增长。

更进一步，图\ref{Fig.3_2}(a)(c)中，除第三次划分点的具体数值不相同以外，(a)(c) 两种划分策略是基本相同的，尽管如此，由于划分点其具体取值往往数量级庞大，这将进一步造成划分方案数量的增加。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_3.png}}
	\caption{划分子空间个数不同，划分方式基本相同.}
	\label{Fig.3_3}
\end{figure}

图描述了在\ref{Fig.3_3}(a)的划分基础上，\ref{Fig.3_3}(b) 有进行了第4 次空间划分，这时原始数据空间被分别划分为了4 个子空间和5 个子空间。这对于统一编码来说是一个更加难以解决的问题。

受到图形学领域，如光线追踪技术中常用的kd 树分层数据结构的启发，本文提出采用伪满二叉树的形式来表示对原始数据空间任意维度的划分处理以及结果表示，并依据该伪满二叉树进行统一编码。其关键思想是：

\begin{itemize}
    \item 采用二叉树表示划分过程和划分结果。
    \item 每个非叶节点n中都被认为隐式包含一个划分超平面，该划分超平面将数据集分成两部分。由前文所述，划分超平面可由数据对$(\mathbf{p}_n, \emph{p}_n)$ 唯一表示，其中$\mathbf{p}_n$ 是当前问题域特征空间中的某个特征，$\emph{p}_n$则是$\mathbf{p}_n$ 轴上任意的取值，以$\emph{p}_n$ 为划分点，该超平面垂直于$\mathbf{p}_n$ 轴。
    \item 空节点被引入到该二叉树中以构成逻辑意义上的“满二叉树”，即：伪满二叉树。假设伪满二叉树拥有相同的树高，则所有的划分方案就可以拥有统一的编码形式。
\end{itemize}

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_4.png}}
	\caption{划分空间的对应伪满二叉树.}
	\label{Fig.3_4}
\end{figure}

如图\ref{Fig.3_4}所示，针对当前二维情况下的空间划分结果，首先通过超平面$(\mathbf{p}_1, \textit{p}_1)$将划分左右两部分，左侧部分包含的数据量实际上是由最终的子数据集(2)(3)(4) 构成的，右侧部分由子数据集(1) 构成。而左侧部分仍通过超平面$(\mathbf{p}_2, \textit{p}_2)$ 进行了进一步的划分，以此类推直到划分到叶子节点。记得注意的是：在该例子中，伪满二叉树的最大树高被指定为(3)(4)节点所在的树高（树高为4），因此，为补齐一颗伪满二叉树，虚线部分所表示的空节点被引入。如果此时指定的伪满二叉树的最大树高为5 时，则(3)(4)节点的下方仍应该补齐两个左右空子节点。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_5.png}}
	\caption{编码后的染色体.}
	\label{Fig.3_5}
\end{figure}

如图\ref{Fig.3_5}所示，编码后的伪满二叉树储存在一个一维数组中，该数组即为本文所使用的染色体。该一维数组中的每个元素将通过如下的方式表示：根节点被存储在下标为0 的数组元素中；假设任意一个节点的下标为i，则其左右孩子节点将分别被存储在下标为2i+1,2i+2 的数组元素中。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_6.png}}
	\caption{染色体内部信息.}
	\label{Fig.3_6}
\end{figure}

同时，如图\ref{Fig.3_6}所示，染色体内部需要记录的额外信息是当前非叶节点的划分超平面$(\textbf{p}_n, \textit{p}_n)$，即划分特征和划分点构成的数据对。通过上述操作可以编码得到一条染色体，其中每一个数组元素被称为基因，一条染色体实际上就是一种基因组合。

\subsubsection{解码}

根据染色体信息解码恢复出新个体的过程是必要的，原因是通过交叉算子、变异算子操作过后的染色体无法被直接评估其优质与否，必须通过将其恢复成为真正的瓶颈分析树个体，才能计算树中每个叶子节点的好坏，从而为整个个体的评判提供基础；

解码过程相对简单，需要完成以下过程：

\begin{itemize}
    \item 以预采集的性能数据集作为当前根节点的完整数据集，建立根节点，并从当前根节点开始，递归地完成接下来的操作。
    \item 找到当前节点对应的染色体下标index，根据当前下标取出染色体中存储的划分超平面信息，如果信息为空，则说明根据当前染色体指示，不再进行当前节点的继续划分，退出当前节点的划分工作；如果信息不为空，则根据取出的划分超平面信息，尝试将当前节点进行划分，如果按照该划分超平面划分得到的左右子节点均满足子节点拥有的最少数据量，则划分成功，其划分后的子节点同样完成步骤2中的操作，否则，当前的划分超平面失效，终止该节点的划分工作。
    \item 递归完成所有节点的划分工作，退出整个流程。
\end{itemize}

\subsection{适应度计算}
\label{sec:FitnessCalculate}

适应度评估对于遗传算法在种群迭代过程中起到了至关重要的作用。它决定了整个种群的进化方向，它引导着个体朝着提高种群整体适应度的方向发展。如公式\ref{eq:PartitionFitness} 所示，个体适应度函数$F(\ )$ 表示某种将原始数据空间P 划分成n个子空间的划分方案的好坏程度，其中n个子空间分别表示为：$\mathcal{P}_0^{sub}, \mathcal{P}_1^{sub}, ..., \mathcal{P}_n^{sub}$。

\begin{equation} \label{eq:PartitionFitness}
	F(\mathcal{P}\rightarrow(\mathcal{P}_0^{sub}, \mathcal{P}_1^{sub}, ..., \mathcal{P}_n^{sub})) = \sum_{i=0}^n f(\mathcal{P}_i^{sub})
\end{equation}

其中，$f(\mathcal{P}_i^{sub})$表示子集$\mathcal{P}_i^{sub}$所在叶子节点的适应度函数，在之后的讨论中，$F(\ )$和$f(\ )$ 被称为个体适应度函数和叶子节点适应度函数。

经过前面的讨论，根据\cite{Zhang:2018:AIP:3208159.3208178} 中关于瓶颈集的定义，只能得出一个布尔值的结果，即：当前叶子节点是否能够识别出瓶颈，这无法为进一步适应度的计算提供帮助。本文需要的是具有连续数值衡量标准的方法来获取当前叶子节点的好坏，无论该叶子节点能否识别出瓶颈集合，都应该拥有其相应的适应度函数得分（或者称为数值）。

事实上，在某个叶子节点能否识别出性能瓶颈只能作为评判叶子节点适应度好坏的充分不必要条件。也就是说，能够识别出性能瓶颈的叶子节点，计算其适应度函数的数值，它的得分一定是较高的，但是适应度函数数值的比较总是在相互比较重完成的，这表明适应度函数数值较高的叶子节点并不一定代表在它的数据集范围内找到了性能瓶颈。为进一步说明问题，本文列举了如下几种情况进行详细讨论：

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_7.png}}
	\caption{子节点中均未识别出性能瓶颈.}
	\label{Fig.3_7}
\end{figure}

如图\ref{Fig.3_7}所示，即使在\ref{Fig.3_7}(a) 和\ref{Fig.3_7}(b) 上都无法确认识别出瓶颈，本文仍然认为图\ref{Fig.3_7}(b) 的划分情况要优于\ref{Fig.3_7}(a)的划分情况。因为在\ref{Fig.3_7}(b) 中各排序后的特征变量重要性数值的最大下降落差要大于\ref{Fig.3_7}(a)中的最大落差。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_8.png}}
	\caption{子节点中均识别出性能瓶颈.}
	\label{Fig.3_8}
\end{figure}

如图\ref{Fig.3_8}所示，即使\ref{Fig.3_8}(a) 和\ref{Fig.3_8}(b) 均识别到了瓶颈（红色部分表示识别到的瓶颈），本文依然认为\ref{Fig.3_8}(b) 的划分情况比\ref{Fig.3_8}(a) 的划分情况要好。这是因为在\ref{Fig.3_8}(b) 中可以唯一确认出一个极度影响绘制性能的因素。
综上所述，本文将采用如下原则设计个体适应书函数$F(\ )$和叶子节点适应度函数$f(\ )$:

\begin{itemize}
    \item 采用连续性函数模型描述个体适应度函数$F(\ )$，保证任意两种划分方案顺利完成其适应度好坏的比较。
    \item 当前特征空间中所有特征的变量重要性数值VI以及其整体分布情况应该决定叶子节点变量重要性函数$f(\ )$ 的计算。具体来说，该原则包含两部分，第一部分要求在子数据集空间$\mathcal{P}^{sub}$ 中，重要的特征（即：公式\ref{eq:SubspaceFitness} 中的重要参数，详细定义将在随后给出）的个数越趋近于1，则持有$\mathcal{P}^{sub}$ 的叶子节点其适应度函数计算结果越高；第二部分要求$f(\ )$ 的计算应与一个距离成正相关。这个距离为重要特征的变量重要性、不重要特征的变量重要性分别和平均变量重要性之间距离的绝对值之和。
    \item 子数据集空间$\mathcal{P}^{sub}$ 的数据量也应该被考虑进来以防止划分空间朝着最小数据集的方向发展。也就是说，本文并不希望瓶颈分析树的高度过于大，这意味着子空间个数的进一步增加，这不利于帮助开发人员进行整体优化工作
\end{itemize}

基于上述原理，本文设计公式\ref{eq:SubspaceFitness}描述$f(\mathcal{P}_i^{sub})$，该公式具体由三个因素决定：

\begin{equation} \label{eq:SubspaceFitness}
	f(\mathcal{P}^{sub}) = f_1(\mathcal{P}^{sub})*f_2(\mathcal{P}^{sub})*f_3(\mathcal{P}^{sub})
\end{equation}

其中$f_1(\mathcal{P}^{sub}), f_2(\mathcal{P}^{sub}), f_3(\mathcal{P}^{sub})$ 分别从3个不同的方面影响了$f(\mathcal{P}_i^{sub})$ 的最终计算数值，详细计算公式参见公式\ref{eq:DetailFitness}:

\begin{equation} \label{eq:DetailFitness}
\begin{cases}
	f_1(\mathcal{P}^{sub}) = w_1 * \frac{N-N_{sig}}{N-1} + w_2 * \frac{N-N_{med}}{N-1} + w_3 * \frac{n_{tri}}{N-1}\\
	f_2(\mathcal{P}^{sub}) = \sqrt[3]{1 - \frac{I_{tri}^{avg}}{I_{sig}^{avg}}}\\
	f_3(\mathcal{P}^{sub}) = \sqrt[3]{\frac{|\mathcal{P}^{sub}|}{|\mathcal{P}|}}
\end{cases}
\end{equation}

$f_1$用来描述处在不同重要程度的参数个数对$f(\ )$ 计算的影响。单纯将参数划分为重要和非重要参数并不是理想的方式，因此文本采用三段法的划分方式根据其重要程度对参数进行区分。如图\ref{Fig.3_9} 所示，所有参数根据其变量重要性VI 的计算结果进行降序排序，假设$s_{max}$是当前子数据集$f(\mathcal{P}_i^{sub})$下最大VI 值的具体数值，则区间$(0,s_{max}]$可以被划分为三个子区间：$(0, r_1*s_{max}], (r_1*s_{max}, r_2*s_{max}], (r_2*s_{max}, s_{max}]$，其中$r_1$ 和$r_2$是满足$0<r_1<r_2<1$的两个限制参数，由用户自定义决定。基于上述三个区间，所有参数可被相应的归为不同种类的参数：重要参数，灰色参数以及不重要参数。本文设置$r_1 = 0.25$，$r_2 = 0.75$。

$f2(\ )$通过重要参数的平均变量重要性与不重要变量重要性的平均变量重要性的比率印象影响$f(\ )$的计算结果；

$f3(\ )$用来控制划分子空间的个数。

在上述三个子公式中，本文认为$f1(\ )$ 在影响$f(\ )$ 计算时应该占有更重要的比重，因此在设计$f2(\ )$ 和$f3(\ )$时引入了开立方操作，以减少它们对$f(\ )$ 的影响。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/Fig_3_9.png}}
	\caption{三段划分方式.}
	\label{Fig.3_9}
\end{figure}


\subsection{遗传算子}
\label{sec:GAOperator}

\subsubsection{基本目标}

本章的基本目标是通过构建合理的遗传算子操作，生成并保留更优秀的种群个体，使得种群整体逐渐向更高适应度的方向收敛，直至收敛最优解。根据算法概述讨论可知，新一代种群是由上一代种群通过遗传算子操作得到的，因此，如何构建合理的遗传算子操作是本章关注的重点内容。

\subsubsection{选择算子}
\label{sec:GAOperatorSelector}

选择算子表示基于适应度的优胜略汰的过程。其具体表现在两个方面：一方面通过选择算子把优质个体直接遗传到下一代，另一方面，通过选择算子选择一定比例的个体通过配对交叉产生新的个体，这间接利用到选择算子，因此选择算子有时也被称作再生算子。

目前，常用的选择算子方法包括：随机遍历抽样法、局部选择法和适应度比例法。随机遍历抽样法表示在当前种群中，每个个体被选中的概率相等。由于它在进行选择操作时采用随机等概率的方式抽取个体，所以对不同适应度的个体机会均等，故可以认为多样性相对持久[\cite{}]，但其缺点在于太过随机，导致整个种群的迭代规律不明显；在局部选择法中，通常表示在规模N 的个体中选取适应度数值最高的前$n$个个体（$n < N$），这使得适应度最好的前n 个个体被完整的保留下来，而适应度处于末位的个体被直接淘汰，该方法改进了前一种方法种群迭代规律不明显的缺点，加快了种群收敛速度，但其缺点在于很容易产生超级个体，致使种群很容易收敛于一个局部最优解；而在适应度比例法该方法中，每个个体的被选中概率与其适应度和其适应度成比例，常用的比例模型为轮盘赌模型：假设当前种群的规模为n，每个个体用$i$表示$(i = 1, 2, …n)$，$p(i)$表示个体$i$被选中的概率，其计算公式参见\ref{eq:lotteGame}:

\begin{equation} \label{eq:lotteGame}
	p_i=\sqrt[c]{\frac{f_i}{\sum_{j=1}^{n} f_j}}
\end{equation}

显然，以这种方式得到的概率反映了个体$i$ 的适应度在整个种群个体适应度综合中所占的比例。个体适应度越大，其被选中的概率就越高，但并不表示一定会被选中，同时，本文进一步通过控制参数$c$ 来达到控制种群多样性的目的。

\subsubsection{交叉算子}
\label{sec:CrossoverOperator}

交叉算子根据交叉概率将种群中任意选取的两个个体随机的进行若干基因的交换，并产生新的两个染色体（基因组合），期望将有益基因组合在一起旨在产生更优秀的个体。若干基因的交换表明交叉算子有不同的交叉执行方案，根据本文的编码方式可以进行单点交叉和多点交叉。由于本文的编码方式不属于二进制编码[\cite{}] 和浮点数编码[\cite{}]，而更类似于符号编码[\cite{}]，因此遗传算法中另外两种交叉方案：均匀交叉[\cite{}] 和算数交叉[\cite{}] 并不适用。这里引入了几个新名词：交叉概率，单点交叉和多点交叉，在详细阐述交叉算子操作之前，本文先解释何为交叉概率。

交叉概率是指针对当前已经被选择出的两个用于交叉的双亲个体真正进行交叉操作的概率，也就是说，即使通过选择算子选择产生出一对用于交叉操作的双亲个体，该双亲个体也不一定真正执行交叉操作产生新的两个个体。[\cite{wanglan}]中研究并提出交叉概率在整个遗传迭代过程中如果保持恒定不变会降低遗传算法性能，作者表示迭代初期需要较大的交叉概率以造成种群的足够扰动，从而增强遗传算法的搜索能力，而在迭代后期采用更小的交叉概率以避免破坏已有优良基因。

本文采用公式\ref{eq:CrossOverPro}计算每代种群的双亲交叉概率:

\begin{equation} \label{eq:CrossOverPro}	
    P_c=(1.0-\frac{I_{cur}}{I_{max}})\sqrt{\frac{\sigma_{fit}^2+(F_{big}-F_{small})^2}{2*(F_{max}-F_{min})^2}}
\end{equation}

其中，$P_c$表示当前种群中某个双亲的交叉概率，$I_{cur}$表示当前种群的遗传迭代次数，$I_{max}$表示最大遗传迭代次数，$f_{max}$、$f_{min}$和$f_{avg}$分别表示当前整个种群中最大适应度值、最小适应度值和平均适应度值，$f_{cmax}$ 表示当前双亲的较大适应度值。该公式保证遗传算法收敛到最优解的性质在[\cite{wanglan}]中给出了详细的证明和数学推导。

图\ref{Fig.3_10}(a)、\ref{Fig.3_10}(b) 分别为单点、多点交叉示意图。单点交叉是指在参与交叉的两条染色体上仅选取一对等位基因进行交换的操作；多点交叉是指在参与交叉的两条染色体上选取多对等位基因进行交换的操作。这两种方式仅在选取交换基因的个数上有差异，具体根据不同的研究问题可以采取不同的交叉方式。本文会在实验部分验证采用哪种方案将更有利于解决本文关注的问题域。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=.9\linewidth]{figures/Fig_3_10.png}}
	\caption{单点交叉与多点交叉.}
	\label{Fig.3_10}
\end{figure}

染色体中所有基因被选中为交换基因点采取等概率选取。根据\ref{sec:Coding} 节阐述的编码过程，每个基因点位上的超平面选取对于空间划分的作用并不会因为其位置的不同而不同，因此这里采用等概率方式进行选择。%（事实上做过对比试验，等概率VS 与树深有关的概率，实验失败）

\subsubsection{变异算子}
\label{sec:GAOperatorMutex}

变异算子用来保证种群在迭代过程中的个体多样性，防止收敛速度过快导致的进化朝着局部最优解的方向进行。变异作为小概率事件在自然界的生物进化中起到不可替代的作用：变异的方向是完全不确定的，这是生物多样性的重要原因，由于方向的不确定性，变异个体可能更差，更差的个体通过本算法逐渐被淘汰，也可能更优，这为本算法产生优质个体提供了另外一种途径。

本文算法通过等概率随机选取种群个体，在此基础上等概率随机选择染色体的非叶节点基因，在该基因上进行其划分特征和划分点的等概率随机变化完成对随即变异的模拟。

\subsection{其他}

\subsubsection{迭代终止条件}

%\begin{equation} \label{eq:split}
	%p_s^i=p_{min}+\frac{i*(p_{max}-p_{min})}{N_s+1}
%\end{equation}

\subsubsection{等位基因交换失效}

\subsubsection{种群序列化与反序列化}

为进一步降低种群训练的计算成本与时间成本，本文利用序列化与反序列化技术将算法生成的初始种群进行保存与再现。根据本文提出的算法流程，在算法起始阶段，会生成一定规模的初始种群，初始种群实际上是若干瓶颈分析树的集合，对初始种群的序列化主要对每个瓶颈分析树的序列化，考虑到序列化信息的压缩问题，本文并未直接对瓶颈分析树进行序列化，而是结合编码信息可以唯一确定一棵瓶颈分析树这一特性，将瓶颈分析树的编码信息和适应度信息进行序列化保存。其中序列化模型内具体保存染色体上各基因点上的划分特征信息、划分点信息、节点类型信息以及参数变量重要性信息。这些信息均是在种群初始化阶段计算得到的，然而每次重复生成这些信息所消耗的计算时间是十分可观的，并且初始种群的信息一旦生成便可重复利用。利用这些信息进行反序列过程可以迅速重建出原始的初始种群，这极大地提高了本文方法的分析效率。

\subsection{本章小结}

本章主要介绍了本文的主要工作，详细介绍了基于贪心策略和类遗传策略的复杂绘制系统性能识别算法其全部流程和具体实现细节。重点介绍类遗传策略，按照遗传算法的核心思想划分，首先对于初始种群的生成进行了详细的介绍，其次对种群个体的编码和解码方式进行了详细的阐述，推导其实现过程，之后根据本文研究的具体问题推导并设计了适应度函数，并进一步讨论了本文遗传算子的具体实现方式，最后对本文在完成具体算法时的其他工作进行了补充。

\section{实验结果与分析}

\subsection{实验概述}

本章针对第\ref{sec:CoreAlgorithm}章推导过程中提出的问题与猜想，设计相应的实验内容和实验场景给予验证和对比。本文主要提出了基于特征空间划分的算法级绘制性能瓶颈识别技术，用来解决在复杂绘制系统中无法确认全局性能瓶颈的问题，由第\ref{sec:CoreAlgorithm} 章的讨论可知，局部性能瓶颈识别的核心在于特征空间的合理划分，这要求划分后的子空间在重新计算各参数的变量重要性时，其变量重要性仍保证计算结果的稳定性，因此第一个实验被设计用来证明本文算法在任意局部子空间，参数变量重要性的计算稳定性；实验二包含两个子实验，共同验证本文预采集性能数据的正确性，为之后的实验内容提供验证基础；第三个实验针对\ref{sec:GenInitialPopulation} 部分提出的关于初始种群优化生成算法给予对比验证；第四个实验设计用来验证单点交叉和多点交叉针对本文不同的多个绘制场景的影响；最后，实验验证本文算法优化局部性能瓶颈识别过程的有效性；

\subsection{实验环境}

本文实验主要软硬件环境配置如表\ref{table:ExperimentalEnvironment} 所示：

\begin{table}
    \begin{center}
        %EXCEL表格直接复制过来的 注意数学符号需要加上$...$
        \begin{tabular}{|c|c|c|}
          \hline
          %跨行（将两行合并为一行） 第一个参数指明跨几行 记得下一行对应位置空出来 不然会重叠
          \multirow{3}{*}{硬件环境} & CPU & Intel(R)Core(TM)i7-6900k@3.2GHz \\
          \cline{2-3}
           & 内存 & 32.00GB \\
          \cline{2-3}
          & 显卡 & NVIDIA GeForce GTX-1080 \\
          \hline
          \multirow{3}{*}{软件环境} & 操作系统 & Windows 10 Home \\
          \cline{2-3}
           & 编译器 & Visual Studio 2015 \\
          \cline{2-3}
          & 开发库 & OpenGL 4.5 \\
          \hline
        \end{tabular}
        \caption{实验软硬件环境}
        \label{table:ExperimentalEnvironment}
    \end{center}
\end{table}

为构建复杂绘制系统的实验环境，本文为绘制场景引入多种绘制算法。本文采用DiningRoom 模型（规模54,011 个三角面片）作为测试绘制场景，并在场景中随机分布300个动态光源与25 个位置随机的静态透明物体，测试场景效果图如图\ref{Fig.DiningRoom} 所示。

本文绘制系统基于延迟渲染框架\cite{Lauritzen2010Deferred}。 在此基础上实现基于光源链表的动态光源算法（LLL 算法）\cite{abdul2016} 以产生大量动态光源的光照效果。实现顺序无关透明渲染算法（OIT算法）\cite{thibieroz2011order} 以完成对场景中透明物体的渲染。同时进一步在场景中引入基于屏幕空间环境光遮挡算法（SSAO 算法）\cite{Bavoil2008Screen}，该算法是基于屏幕像素的图像增强算法，用于进一步优化本文绘制系统的渲染效果。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=1.0\linewidth]{figures/scene_diningroom.png}}
	\caption{测试场景效果图.}
	\label{Fig.DiningRoom}
\end{figure}

上述渲染系统中使用的算法级参数详细介绍如下：

\begin{itemize}
    \item LLL算法：本实验尝试找到光源分布对帧率的影响。因此整个视椎体根据与视点的距离将被划分为三个部分（近距离区域、中间距离区域和远距离区域），分别动态地记录位于这些区域中光源的个数，记为$(N_n, N_m, N_f)$，作为实验输入的算法级参数。另外，光圆半径$R_L$也是另一个被研究的算法级参数。
    \item OIT算法：该算法中引入两个值得被研究的算法级参数。$S_{trans}$ 表示透明物体包围盒投影到屏幕面积之和；$N_{trans}$ 表示可见透明物体的个数；
    \item SSAO算法：该算法中同样引入两个算法级参数：采样半径$R_S$，采样点个数$N_S$。
\end{itemize}

本文采用路径漫游方式预采集得到性能数据集，路径是所有视点位置串联成的一组信息集合。具体过程分为两大步骤：第一步，在当前绘制场景下生成一条遍历整个场景的随机漫游路径记录并保存；第二步，再现当前路径，在路径的任意一点随机扰动各算法级参数的有效取值并保存，同时保存当前视点的信息，包括视点的世界坐标信息：$(x, y, z)$ 以及视点的方向信息：$(\alpha, \beta)$，最后保存记录下当前绘制一帧消耗的时间$t$，最终得到一组包含14 维的性能数据集。数据集各参数说明参见表\ref{table:Parameters}：

\begin{table}[!h]
    \tiny
    \centering
    \begin{tabular}{|l|c|c|c|}
      \hline
      No. & 参数 & 数据类型 & 有效取值范围 \\
      \hline
      1 & $x$ & float & [-2.0, 2.0] \\
      \hline
      2 & $y$ & float & [-2.0, 2.0] \\
      \hline
      3 & $z$ & float & [-6.0, 6.0] \\
      \hline
      4 & $\alpha$ & float & [$0, 2\pi$] \\
      \hline
      5 & $\beta$ & float & [$0, \pi$] \\
      \hline
      6 & $N_n$ & integer & [0, 16] \\
      \hline
      7 & $N_m$ & integer & [0, 97] \\
      \hline
      8 & $N_f$ & integer & [0, 226] \\
      \hline
      9 & $R_L$ & float & [1.0, 1.4] \\
      \hline
      10 & $S_{trans}$ & integer & [0, 13523000] \\
      \hline
      11 & $N_{trans}$ & integer & [0, 25] \\
      \hline
      12 & $R_S$ & integer & [7, 18] \\
      \hline
      13 & $N_S$ & integer & [4, 30] \\
      \hline
      14 & $t$ & float & [4.26701, 28.39550] \\
      \hline
    \end{tabular}
    \caption{参数配置}
    \label{table:Parameters}
\end{table}

\subsection{实验设计与结果}

\subsubsection{验证基于场景稀疏采样数据的正确性}

\textbf{实验目的}

本文预采集性能数据集是基于测试场景的稀疏采样结果，该实验用以验证本文为后续算法提供的规模为150,000条数据的性能数据集能够描述测试场景。基于测试场景的稀疏采样是指对场景所在参数空间$\mathbb{P}=\{\mathbf{V}(\mathbf{p}_1)\times \mathbf{V}(\mathbf{p}_2)\times ... \times \mathbf{V}(\mathbf{p}_N)\}$的稀疏采样。稀疏采样是有必要的，由于本文方法对于算法级参数的个数可扩展，即当参数空间的维度不断增加时，参数空间的规模将呈现指数级的增长，以前6维的算法级参数为例，假设$x, y, z, \alpha, \beta, N_n$的有效取值为10个，则此时的有效组合共有1,000,000 个，参数空间的规模会随着算法级参数的增加而成指数级增长，而海量的数据规模将极大地减慢算法的效率。而实际上，对参数空间$\mathbb{P}$ 的完全采样是没有必要的，由于参数空间中邻近数据对构建随机森林学习模型的贡献能力是相似的，随着邻近数据数量的不断增加，这种贡献能力将逐渐趋于饱和，而根据\cite{Breiman2001Random}可知，随机森林模型对欠采样甚至数据缺失时仍维持精确度。因此本文在进行大量测试之后将性能数据集规模确定在150,000 个。

\textbf{输入数据}

本文根据前文中描述的漫游路径方式，预先在测试场景中随机生成4条漫游路径，每条漫游路径根据不同的随机移动方式遍历整个测试场景。在这些漫游路径上分别收集150,000 条性能数据构成4 组性能数据集。本文通过4 组性能数据集分别计算出各算法级参数的变量重要性结果，结果如表\ref{tab:StableVI}所示。

\textbf{结果分析}

\begin{table}[!h]
    \tiny
    \newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
          \hline
            & x & y & z & $\alpha$ & $\beta$ & $N_n$ & $N_m$ & $N_f$ & $R_L$ & $R_s$ & $N_s$ & $A_o$ & $N_o$ \\
          \hline
          1 & \tabincell{c}{0.446\\(1.0\%)} & \tabincell{c}{0.465\\(1.5\%)}&\tabincell{c}{0.782\\(0.7\%)}&\tabincell{c}{0.322\\(7.3\%)}&\tabincell{c}{0.676\\(4.5\%)}&\tabincell{c}{0.275\\(2.4\%)}&\tabincell{c}{2.000\\(0.1\%)}&\tabincell{c}{1.766\\(2.4\%)}&	\tabincell{c}{2.139\\(0.1\%)}&\tabincell{c}{0.060\\(1.2\%)}&\tabincell{c}{1.900\\(0.6\%)}&\tabincell{c}{1.916\\(0.5\%)}&\tabincell{c}{0.740\\(0.5)\%}\\
          \hline
          2 & \tabincell{c}{0.446\\(1.2\%)}&\tabincell{c}{0.468\\(2.3\%)}&	\tabincell{c}{0.761\\(1.9\%)}&	\tabincell{c}{0.325\\(8.5\%)}&	\tabincell{c}{0.647\\(0.04\%)}&	\tabincell{c}{0.289\\(4.0\%)}&	\tabincell{c}{1.986\\(0.8\%)}&	\tabincell{c}{1.779\\(1.7\%)}&	\tabincell{c}{2.138\\(0.05\%)}&	\tabincell{c}{0.058\\(3.3\%)}&	\tabincell{c}{1.888\\(1.3\%)}&	\tabincell{c}{1.898\\(0.4\%)}&	\tabincell{c}{0.761\\(2.3\%)}\\
          \hline
          3 & \tabincell{c}{0.445\\(0.8\%)	}&\tabincell{c}{0.462\\(0.9\%)	}&\tabincell{c}{0.779\\(0.3\%)	}&\tabincell{c}{0.317\\(5.7\%)	}&\tabincell{c}{0.641\\(0.9\%)	}&\tabincell{c}{0.290\\(4.1\%)	}&\tabincell{c}{1.966\\(1.8\%)	}&\tabincell{c}{1.757\\(2.9\%)	}&\tabincell{c}{2.136\\(0.1\%)	}&\tabincell{c}{0.058\\(2.4\%)	}&\tabincell{c}{1.902\\(0.5\%)	}&\tabincell{c}{1.925\\(1.0\%)	}&\tabincell{c}{0.723\\(2.8\%)}
 \\
          \hline
          4 & \tabincell{c}{0.428\\(3.0\%)	}&\tabincell{c}{0.436\\(4.7\%)	}&\tabincell{c}{0.784\\(0.9\%)	}&\tabincell{c}{0.235\\(11.5\%)	}&\tabincell{c}{0.624\\(3.6\%)	}&\tabincell{c}{0.249\\(10.2\%)	}&\tabincell{c}{2.055\\(2.7\%)	}&\tabincell{c}{1.937\\(7.0\%)	}&\tabincell{c}{2.136\\(0.05\%)	}&\tabincell{c}{0.062\\(5.0\%) }&\tabincell{c}{1.958\\(2.4\%)	}&\tabincell{c}{1.884\\(1.2\%)	}&\tabincell{c}{0.751\\(1.0\%)}
 \\
          \hline
          average & 0.441 & 0.458 & 0.776 & 0.300 & 0.647 & 0.278 & 2.002 & 1.810 & 2.137 & 0.059 & 1.912 & 1.906 & 0.744
 \\

          \hline
    \end{tabular}
    \caption{稀疏采样数据的VI计算结果}
    \label{tab:StableVI}
\end{table}

如表\ref{tab:StableVI}所示，表中前4行数据是13个算法级参数的VI计算结果（表中仅保留到小数点后3位），第5行数据是某算法级参数4组数据VI计算结果的平均值，括号中的数值表示该VI值与其对应平均值的偏差百分比。

\begin{figure}[!h]
	\centering{
	\includegraphics[width=.9\linewidth]{figures/Fig_count.png}}
	\caption{VI值百分比偏差统计.}
	\label{Fig.count}
\end{figure}

由分析可知，基于测试场景的稀疏采样是行之有效的。有效性具体表现在：本文预采集性能数据集的数据量为150,000时，通过4 组不同的性能数据集计算出各个算法级参数的VI 值是基本稳定的，对应平均值的偏差百分比保持在20.0\%以内，这是保证VI稳定性的阈值上限。进一步由图\ref{Fig.count}统计表\ref{tab:StableVI}中的偏差百分比可知，此时的偏差百分比大多集中在(0.0\%, 3.0\%]中间，这保证了VI计算结果是稳定可靠的，也说明了本文基于场景稀疏采样得到性能数据集的正确性。

\subsubsection{验证VI计算结果的稳定性}

\textbf{实验目的}

该实验用来证明VI计算结果是稳定的，VI计算结果是否稳定直接导致基于特征空间划分的结果可靠与否。由第\ref{sec:CoreAlgorithm} 章分析可知，性能数据集根据不同的划分超平面被划分到不同子数据集，因此子空间的数据规模会不断减小，然而此数据规模存在下限，这是由于：当参与VI计算的输入数据量小于一定阈值时，VI的计算结果不再稳定。因此，本文方法需要确保任意数据子集中VI 计算结果的稳定性。换言之，本文需要通过该实验明确阈值的具体数值，使得子数据集参与VI计算的数据量小于该阈值时，VI 的计算结果将不再稳定。

\textbf{输入数据}

该实验从150,000条的性能数据集中随机抽取数据记录，分别生成7组具备不同数据规模的性能数据集，数据规模分别为5,000 条，6,000条，7,000条，8,000条，9,000 条，50,000条，100,000条。随后将7组性能数据集分别作为VI 计算的输入数据进行各算法级参数VI值的计算。上述VI计算过程重复10次，并记录下各参数VI平均值。

\textbf{结果分析}

如表\ref{tab:Minimum Data Size}所示，表中每行数据是13个算法级参数VI 计算结果的平均值，而括号内数据表示该数值与表\ref{tab:StableVI}中相对应VI 平均值的偏差百分比。

由分析可知，当参与计算VI值的数据量小于7,000条时，参数$R_s$的VI计算结果其偏差百分比均大于20.0\%，并且进一步随着数据量的减少，其偏差百分比逐渐增大至33\%。 由此分析可知，当数据量小于7,000条时，VI的计算结果价格不再保证稳定。因此，本文在进行瓶颈分析树构建时要求任意节点的数据量至少包含8,000条记录。

\begin{table}[!h]
    \tiny
    \newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
          \hline
            & x & y & z & $\alpha$ & $\beta$ & $N_n$ & $N_m$ & $N_f$ & $R_L$ & $R_s$ & $N_s$ & $A_o$ & $N_o$ \\
          \hline
          5000 & \tabincell{c}{0.455\\(3.1\%)} & \tabincell{c}{0.468\\(2.1\%)}&\tabincell{c}{0.779\\(0.3\%)}&\tabincell{c}{0.317\\(5.9\%)}&\tabincell{c}{0.637\\(1.6\%)}&\tabincell{c}{0.277\\(0.3\%)}&\tabincell{c}{2.019\\(0.9\%)}&\tabincell{c}{1.768\\(2.3\%)}&	\tabincell{c}{2.142\\(0.2\%)}&\tabincell{c}{0.079\\\bfseries{(33\%)}}&\tabincell{c}{1.902\\(0.5\%)}&\tabincell{c}{1.941\\(1.8\%)}&\tabincell{c}{0.719\\(3.3)\%}\\
          \hline
          6000 & \tabincell{c}{0.459\\(4\%)}&\tabincell{c}{0.471\\(2.9\%)}&	\tabincell{c}{0.785\\(1.1\%)}&	\tabincell{c}{0.329\\(9.7\%)}&	\tabincell{c}{0.638\\(1.3\%)}&	\tabincell{c}{0.289\\(3.8\%)}&	\tabincell{c}{2.035\\(1.7\%)}&	\tabincell{c}{1.785\\(1.4\%)}&	\tabincell{c}{2.147\\(0.4\%)}&	\tabincell{c}{0.075\\\bfseries{(25.8\%)}}&	\tabincell{c}{1.895\\(0.9\%)}&	\tabincell{c}{1.92\\(0.7\%)}&	\tabincell{c}{0.713\\(4.2\%)}\\
          \hline
          7000 & \tabincell{c}{0.452\\(2.5\%)	}&\tabincell{c}{0.466\\(1.8\%)	}&\tabincell{c}{0.78\\(0.4\%)	}&\tabincell{c}{0.325\\(8.3\%)	}&\tabincell{c}{0.642\\(0.8\%)	}&\tabincell{c}{0.279\\(0.2\%)	}&\tabincell{c}{2.007\\(0.3\%)	}&\tabincell{c}{1.777\\(1.8\%)	}&\tabincell{c}{2.089\\(2.2\%)	}&\tabincell{c}{0.072\\\bfseries{(20.8\%)}	}&\tabincell{c}{1.851\\(3.2\%)	}&\tabincell{c}{1.955\\(2.6\%)	}&\tabincell{c}{0.718\\(3.5\%)}
 \\
          \hline
          8000 & \tabincell{c}{0.454\\(2.9\%)	}&\tabincell{c}{0.463\\(1.2\%)	}&\tabincell{c}{0.78\\(0.4\%)	}&\tabincell{c}{0.322\\(7.5\%)	}&\tabincell{c}{0.633\\(2.2\%)	}&\tabincell{c}{0.284\\(2.2\%)	}&\tabincell{c}{2.016\\(0.7\%)	}&\tabincell{c}{1.78\\(1.6\%)	}&\tabincell{c}{2.128\\(0.5\%)	}&\tabincell{c}{0.068\\\bfseries{(15\%)} }&\tabincell{c}{1.875\\(1.9\%)	}&\tabincell{c}{1.926\\(1.1\%)	}&\tabincell{c}{0.724\\(2.7\%)}
 \\
          \hline
          9000  & \tabincell{c}{0.457\\(3.6\%)	}&\tabincell{c}{0.463\\(1.1\%)	}&\tabincell{c}{0.782\\(0.7\%)	}&\tabincell{c}{0.32\\(6.8\%)	}&\tabincell{c}{0.634\\(2\%)	}&\tabincell{c}{0.274\\(1.4\%)	}&\tabincell{c}{1.983\\(0.9\%)	}&\tabincell{c}{1.766\\(2.5\%)	}&\tabincell{c}{2.094\\(2\%)	}&\tabincell{c}{0.064\\\bfseries{(7.8\%)}	}&\tabincell{c}{1.918\\(0.3\%)	}&\tabincell{c}{1.926\\(1\%)	}&\tabincell{c}{0.725\\(2.5\%)}
 \\

          \hline
          50000  & \tabincell{c}{0.456\\(3.3\%)	}&\tabincell{c}{0.465\\(1.5\%)	}&\tabincell{c}{0.779\\(0.4\%)	}&\tabincell{c}{0.323\\\bfseries{(7.8\%)}	}&\tabincell{c}{0.634\\(2\%)	}&\tabincell{c}{0.284\\(2.1\%)	}&\tabincell{c}{2.011\\(0.5\%)	}&\tabincell{c}{1.766\\(1.9\%)	}&\tabincell{c}{2.129\\(0.4\%)	}&\tabincell{c}{0.057\\(4.4\%)	}&\tabincell{c}{1.897\\(0.8\%)	}&\tabincell{c}{1.928\\(1.2\%)	}&\tabincell{c}{0.723\\(2.8\%)}
 \\

          \hline
          100000 & \tabincell{c}{0.455\\(3.2\%)	}&\tabincell{c}{0.463\\(1.1\%)	}&\tabincell{c}{0.777\\(0.1\%)	}&\tabincell{c}{0.323\\\bfseries{(7.7\%)}	}&\tabincell{c}{0.635\\(1.9\%)	}&\tabincell{c}{0.283\\(1.7\%)	}&\tabincell{c}{2.008\\(0.3\%)	}&\tabincell{c}{1.776\\(1.9\%)	}&\tabincell{c}{2.135\\(0.1\%)	}&\tabincell{c}{0.057\\(4.6\%)	}&\tabincell{c}{1.894\\(1\%)	}&\tabincell{c}{1.922\\(0.9\%)	}&\tabincell{c}{0.723\\(2.8\%)}
\\

          \hline
    \end{tabular}
    \caption{VI稳定性的最小数据量}
    \label{tab:Minimum Data Size}
\end{table}

\subsubsection{验证生成初始种群优化算法的有效性}

\textbf{实验目的}

该实验用来验证本文针对类遗传策略提出的初始种群优化的有效性。

\textbf{结果分析}

\subsubsection{对比单点交叉与多点交叉对种群收敛速度的影响}

\textbf{实验目的}

\textbf{结果分析}

\subsubsection{验证类遗传策略识别局部性能瓶颈的有效性}

\textbf{实验目的}

\textbf{结果分析}

\subsection{本章小结}

\section{总结与展望}

本论文在基于数据挖掘方法的自动识别复杂绘制系统算法级瓶颈的方面进行了进一步的探索。在前人的工作基础上，提出利用性能瓶颈分析树完成特征空间的划分以确定局部性能瓶颈，进一步探究贪心策略和类遗传策略在构建瓶颈分析树的有效性，重点研究类遗传策略构建瓶颈分析树有效性与优势。%我们通过完成初代种群初始化的优化工作加速了遗传算法的收敛过程。其次，本文针对VI 计算对离散变量和连续性变量敏感的现象进行了修正工作，去除离线变量对VI 计算的影响。%（这个同样需要看实验结果）。

在效率方面，由于需要保证一定规模的种群规模以及种群迭代次数，因此本文算法仍然属于离线分析算法；同时在变异算子的自适应概率以及迭代数的自适应方面仍有改进的空间。

\bibliographystyle{plain}%
\bibliography{BottleneckAnalysis_bibfile}

\end{document}
